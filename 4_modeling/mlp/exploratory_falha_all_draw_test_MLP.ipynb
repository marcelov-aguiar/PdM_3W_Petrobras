{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "from typing import List\n",
    "import scipy.stats as sts\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import util\n",
    "from pathlib import Path\n",
    "from sk.replace_column_dataframe import ReplaceColumnDataFrame\n",
    "from sk.norm_standard_scaler import NormStandardScaler\n",
    "import constants.columns_dataframe as const\n",
    "from class_manipulates_path import ManipulatePath\n",
    "from class_preprocessing_refactor import Preprocessing\n",
    "from class_format_data import FormatData\n",
    "util.init()\n",
    "\n",
    "current_path = sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível: []\n",
      "TensorFlow está usando a GPU: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verifique se a GPU está disponível\n",
    "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verifique se o TensorFlow está usando a GPU\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações do TensorFlow relacionadas à GPU:\n",
      "[]\n",
      "TensorFlow está usando a GPU: False\n",
      "Número de GPUs disponíveis: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurações do TensorFlow relacionadas à GPU:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())\n",
    "print(\"Número de GPUs disponíveis:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable(df, column_name, intervalos=None):\n",
    "    \"\"\"\n",
    "    Plota um gráfico de dispersão para uma variável de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "        - df: DataFrame pandas contendo os dados.\n",
    "        - column_name: Nome da coluna que você deseja plotar.\n",
    "        - intervalos: Lista de intervalos para plotar linhas verticais.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(df.index.values, df[column_name].values, color='darkcyan', alpha=0.5)\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel(column_name)\n",
    "    plt.title(f'Gráfico de dispersão para a variável \"{column_name}\"')\n",
    "\n",
    "\n",
    "    # Plotar linhas verticais para cada intervalo\n",
    "    if intervalos:\n",
    "        for intervalo in intervalos:\n",
    "            plt.axvline(x=intervalo, linestyle='--', color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_path = ManipulatePath()\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "\n",
    "format_data = FormatData()\n",
    "\n",
    "path_raw_data = manipulate_path.get_path_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_parquet(manipulate_path.get_path_preprocessing_real_data_all_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0.0    32.679781\n",
       "5.0    30.983203\n",
       "7.0    29.009351\n",
       "1.0     4.797527\n",
       "6.0     1.810310\n",
       "2.0     0.719828\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é possível ver que tem poquíssimas classes normais!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 5., 6., 7.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (X) e os rótulos (y)\n",
    "X = df_preprocessing.drop('class', axis=1)\n",
    "y = df_preprocessing['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:03</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397031.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:04</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397031.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:05</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397032.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:06</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397033.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:07</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397033.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:56</th>\n",
       "      <td>8489354.0</td>\n",
       "      <td>109.7213</td>\n",
       "      <td>1496222.0</td>\n",
       "      <td>73.38219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:57</th>\n",
       "      <td>8489349.0</td>\n",
       "      <td>109.7212</td>\n",
       "      <td>1495828.0</td>\n",
       "      <td>73.38310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:58</th>\n",
       "      <td>8489344.0</td>\n",
       "      <td>109.7210</td>\n",
       "      <td>1495433.0</td>\n",
       "      <td>73.38401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:59</th>\n",
       "      <td>8489338.0</td>\n",
       "      <td>109.7209</td>\n",
       "      <td>1495039.0</td>\n",
       "      <td>73.38493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 15:00:00</th>\n",
       "      <td>8489333.0</td>\n",
       "      <td>109.7207</td>\n",
       "      <td>1494645.0</td>\n",
       "      <td>73.38583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977733 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP\n",
       "timestamp                                                      \n",
       "2014-01-24 09:33:03  18433410.0  116.8718  9397031.0   74.80031\n",
       "2014-01-24 09:33:04  18433410.0  116.8718  9397031.0   74.80031\n",
       "2014-01-24 09:33:05  18433410.0  116.8718  9397032.0   74.80031\n",
       "2014-01-24 09:33:06  18433410.0  116.8718  9397033.0   74.80031\n",
       "2014-01-24 09:33:07  18433410.0  116.8718  9397033.0   74.80031\n",
       "...                         ...       ...        ...        ...\n",
       "2019-04-03 14:59:56   8489354.0  109.7213  1496222.0   73.38219\n",
       "2019-04-03 14:59:57   8489349.0  109.7212  1495828.0   73.38310\n",
       "2019-04-03 14:59:58   8489344.0  109.7210  1495433.0   73.38401\n",
       "2019-04-03 14:59:59   8489338.0  109.7209  1495039.0   73.38493\n",
       "2019-04-03 15:00:00   8489333.0  109.7207  1494645.0   73.38583\n",
       "\n",
       "[977733 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k, X_test, y_train_k, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_k, y_train_k, test_size=0.2, stratify=y_train_k, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = NormStandardScaler(X_train.columns)\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "X_train_k_norm = scaler.transform(X_train_k)\n",
    "\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2017-08-01 16:45:09    1.0\n",
       "2014-03-18 13:35:54    5.0\n",
       "2017-02-26 16:16:24    0.0\n",
       "2019-04-03 03:37:20    0.0\n",
       "2017-07-31 19:05:08    0.0\n",
       "                      ... \n",
       "2018-06-20 17:05:13    0.0\n",
       "2017-02-27 08:52:43    7.0\n",
       "2018-06-21 15:41:24    7.0\n",
       "2014-03-18 17:10:15    5.0\n",
       "2014-03-14 17:47:27    0.0\n",
       "Name: class, Length: 547530, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nn_1 = ReplaceColumnDataFrame(const.TARGET, const.MAPPING_TWO_CLASSES).transform(pd.DataFrame(y_train))[\"class\"]\n",
    "\n",
    "y_train_k_nn_1 = ReplaceColumnDataFrame(const.TARGET, const.MAPPING_TWO_CLASSES).transform(pd.DataFrame(y_train_k))[\"class\"]\n",
    "\n",
    "y_test_nn_1 = ReplaceColumnDataFrame(const.TARGET, const.MAPPING_TWO_CLASSES).transform(pd.DataFrame(y_test))[\"class\"]\n",
    "\n",
    "y_val_nn_1 = ReplaceColumnDataFrame(const.TARGET, const.MAPPING_TWO_CLASSES).transform(pd.DataFrame(y_val))[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-20 01:17:06</th>\n",
       "      <td>-1.748677</td>\n",
       "      <td>-0.712923</td>\n",
       "      <td>-1.253200</td>\n",
       "      <td>-1.075840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-20 20:18:21</th>\n",
       "      <td>1.197046</td>\n",
       "      <td>0.628302</td>\n",
       "      <td>1.535948</td>\n",
       "      <td>0.359248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-19 14:13:39</th>\n",
       "      <td>-1.569386</td>\n",
       "      <td>-0.248792</td>\n",
       "      <td>-0.920018</td>\n",
       "      <td>-0.453377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18 04:58:35</th>\n",
       "      <td>1.130444</td>\n",
       "      <td>0.642377</td>\n",
       "      <td>1.009372</td>\n",
       "      <td>0.624118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-18 23:21:09</th>\n",
       "      <td>-1.469840</td>\n",
       "      <td>-0.468626</td>\n",
       "      <td>-0.866594</td>\n",
       "      <td>-0.861681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26 14:40:47</th>\n",
       "      <td>-0.619117</td>\n",
       "      <td>-3.688628</td>\n",
       "      <td>-1.426019</td>\n",
       "      <td>-0.402692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-18 07:09:17</th>\n",
       "      <td>-1.294946</td>\n",
       "      <td>-0.426604</td>\n",
       "      <td>-0.755625</td>\n",
       "      <td>-0.830392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-18 19:04:41</th>\n",
       "      <td>1.108242</td>\n",
       "      <td>0.658533</td>\n",
       "      <td>1.135461</td>\n",
       "      <td>0.604354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-17 14:58:10</th>\n",
       "      <td>-1.071926</td>\n",
       "      <td>-0.417184</td>\n",
       "      <td>-0.600213</td>\n",
       "      <td>-0.882121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 08:24:22</th>\n",
       "      <td>0.682725</td>\n",
       "      <td>0.677909</td>\n",
       "      <td>-0.982931</td>\n",
       "      <td>1.079598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684413 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP\n",
       "timestamp                                                    \n",
       "2014-03-20 01:17:06 -1.748677 -0.712923  -1.253200  -1.075840\n",
       "2018-06-20 20:18:21  1.197046  0.628302   1.535948   0.359248\n",
       "2014-03-19 14:13:39 -1.569386 -0.248792  -0.920018  -0.453377\n",
       "2018-06-18 04:58:35  1.130444  0.642377   1.009372   0.624118\n",
       "2014-03-18 23:21:09 -1.469840 -0.468626  -0.866594  -0.861681\n",
       "...                       ...       ...        ...        ...\n",
       "2018-04-26 14:40:47 -0.619117 -3.688628  -1.426019  -0.402692\n",
       "2014-03-18 07:09:17 -1.294946 -0.426604  -0.755625  -0.830392\n",
       "2018-06-18 19:04:41  1.108242  0.658533   1.135461   0.604354\n",
       "2014-03-17 14:58:10 -1.071926 -0.417184  -0.600213  -0.882121\n",
       "2017-08-01 08:24:22  0.682725  0.677909  -0.982931   1.079598\n",
       "\n",
       "[684413 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_k_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.3127 - accuracy: 0.8619 - val_loss: 0.2022 - val_accuracy: 0.9139\n",
      "Epoch 2/100\n",
      " 174/8556 [..............................] - ETA: 7s - loss: 0.2040 - accuracy: 0.9167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859/8556 [=========>....................] - ETA: 5s - loss: 0.1921 - accuracy: 0.9215"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Treine o modelo com conjunto de validação e o checkpoint\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m histories\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Avalie o modelo\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "histories = []\n",
    "\n",
    "#learning_rate = 0.7\n",
    "#beta_1 = 0.001\n",
    "#beta_2 = 0.001\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_k_norm):\n",
    "    # Divida os dados em treino e validação\n",
    "    X_train_fold, X_val_fold = X_train_k_norm.iloc[train_index], X_train_k_norm.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_k_nn_1.iloc[train_index], y_train_k_nn_1.iloc[val_index]\n",
    "\n",
    "    # Defina o modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #optimizer = Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    optimizer = 'adam'\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Defina o checkpoint para salvar os pesos\n",
    "    checkpoint = ModelCheckpoint(\"weights.h5\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # Treine o modelo com conjunto de validação e o checkpoint\n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=100, batch_size=64, validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint], verbose=True)\n",
    "    histories.append(history.history)\n",
    "    # Avalie o modelo\n",
    "    _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Acurácia do fold: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia média: 97.20%\n",
      "Desvio padrão da acurácia: 0.71%\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f'\\nAcurácia média: {mean_accuracy*100:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Salvar accuracies em um arquivo JSON\n",
    "with open('accuracies_rede_1.json', 'w') as f:\n",
    "    json.dump(accuracies, f)\n",
    "\n",
    "# Salvar histories em um arquivo JSON\n",
    "with open('histories_rede_1.json', 'w') as f:\n",
    "    json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47909/47909 [==============================] - 56s 1ms/step - loss: 0.2589 - accuracy: 0.8820 - val_loss: 0.1588 - val_accuracy: 0.9271\n",
      "Epoch 2/100\n",
      "  175/47909 [..............................] - ETA: 41s - loss: 0.1795 - accuracy: 0.9194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47909/47909 [==============================] - 56s 1ms/step - loss: 0.1526 - accuracy: 0.9343 - val_loss: 0.1315 - val_accuracy: 0.9405\n",
      "Epoch 3/100\n",
      "47909/47909 [==============================] - 56s 1ms/step - loss: 0.1333 - accuracy: 0.9426 - val_loss: 0.1192 - val_accuracy: 0.9533\n",
      "Epoch 4/100\n",
      "47909/47909 [==============================] - 56s 1ms/step - loss: 0.1222 - accuracy: 0.9475 - val_loss: 0.1147 - val_accuracy: 0.9453\n",
      "Epoch 5/100\n",
      "47909/47909 [==============================] - 55s 1ms/step - loss: 0.1139 - accuracy: 0.9523 - val_loss: 0.1196 - val_accuracy: 0.9446\n",
      "Epoch 6/100\n",
      "47909/47909 [==============================] - 58s 1ms/step - loss: 0.1075 - accuracy: 0.9552 - val_loss: 0.1029 - val_accuracy: 0.9582\n",
      "Epoch 7/100\n",
      "47909/47909 [==============================] - 53s 1ms/step - loss: 0.1045 - accuracy: 0.9566 - val_loss: 0.1108 - val_accuracy: 0.9475\n",
      "Epoch 8/100\n",
      "47909/47909 [==============================] - 53s 1ms/step - loss: 0.1011 - accuracy: 0.9577 - val_loss: 0.0998 - val_accuracy: 0.9570\n",
      "Epoch 9/100\n",
      "47909/47909 [==============================] - 56s 1ms/step - loss: 0.0983 - accuracy: 0.9592 - val_loss: 0.0897 - val_accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "47909/47909 [==============================] - 55s 1ms/step - loss: 0.0958 - accuracy: 0.9599 - val_loss: 0.0865 - val_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "47909/47909 [==============================] - 54s 1ms/step - loss: 0.0925 - accuracy: 0.9613 - val_loss: 0.1037 - val_accuracy: 0.9534\n",
      "Epoch 12/100\n",
      "47907/47909 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Treine o modelo com conjunto de validação e o checkpoint\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_nn_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_nn_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Avalie o modelo\u001b[39;00m\n\u001b[0;32m     23\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_norm, y_test_nn_1)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1777\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1778\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1789\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1790\u001b[0m     )\n\u001b[1;32m-> 1791\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1804\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1806\u001b[0m }\n\u001b[0;32m   1807\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:2195\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 2195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2196\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   2197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2198\u001b[0m         ):\n\u001b[0;32m   2199\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1401\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1402\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1403\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1406\u001b[0m )\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:688\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    687\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:815\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 815\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:794\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    792\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 794\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    797\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    798\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    800\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    801\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    802\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:784\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    783\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 784\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    786\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:581\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    580\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    584\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Defina o modelo\n",
    "# model = Sequential()\n",
    "# \n",
    "# # Adicione as camadas ocultas\n",
    "# model.add(Dense(32, input_dim=4, activation='relu'))  # Camada de entrada com 4 neurônios e ativação ReLU\n",
    "# model.add(Dense(16, activation='relu'))  # Segunda camada oculta com 4 neurônios e ativação ReLU\n",
    "# #model.add(Dense(8, activation='relu'))\n",
    "# #model.add(Dense(8, activation='relu'))\n",
    "# \n",
    "# # Adicione a camada de saída\n",
    "# model.add(Dense(1, activation='sigmoid'))  # Camada de saída com 1 neurônio e ativação Sigmoid para classificação binária\n",
    "# \n",
    "# # Compile o modelo\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \n",
    "# # Defina o checkpoint para salvar os pesos\n",
    "# checkpoint = ModelCheckpoint(\"weights.h5\", monitor='val_loss', save_best_only=True)\n",
    "# \n",
    "# # Treine o modelo com conjunto de validação e o checkpoint\n",
    "# model.fit(X_train_norm, y_train_nn_1, epochs=100, batch_size=10, validation_data=(X_val_norm, y_val_nn_1), callbacks=[checkpoint])\n",
    "# \n",
    "# # Avalie o modelo\n",
    "# _, accuracy = model.evaluate(X_test_norm, y_test_nn_1)\n",
    "# print('Acurácia: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9167/9167 [==============================] - 6s 689us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.973837447156689"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "accuracy_score(y_test_nn_1.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0.0:\n",
      "Precision: 0.9597026440904162\n",
      "Recall: 0.9602633116341178\n",
      "F1-score: 0.9599828959993325\n",
      "\n",
      "Classe 1.0:\n",
      "Precision: 0.9807049359701735\n",
      "Recall: 0.9804268119758538\n",
      "F1-score: 0.9805658542515042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test_nn_1.values, y_pred, average=None)\n",
    "recall = recall_score(y_test_nn_1.values, y_pred, average=None)\n",
    "f1 = f1_score(y_test_nn_1.values, y_pred, average=None)\n",
    "for i in range(len(precision)):\n",
    "    print(f'Classe {np.unique(y_test_nn_1)[i]}:')\n",
    "    print(f'Precision: {precision[i]}')\n",
    "    print(f'Recall: {recall[i]}')\n",
    "    print(f'F1-score: {f1[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = X_train_norm.copy()\n",
    "df_data_train[\"class\"] = y_train\n",
    "df_data_train = df_data_train[~(df_data_train[\"class\"] == 0)].copy()\n",
    "\n",
    "df_data_train_k = X_train_k_norm.copy()\n",
    "df_data_train_k[\"class\"] = y_train_k\n",
    "df_data_train_k = df_data_train_k[~(df_data_train_k[\"class\"] == 0)].copy()\n",
    "\n",
    "df_data_val = X_val_norm.copy()\n",
    "df_data_val[\"class\"] = y_val\n",
    "df_data_val = df_data_val[~(df_data_val[\"class\"] == 0)].copy()\n",
    "\n",
    "df_data_test= X_test_norm.copy()\n",
    "df_data_test[\"class\"] = y_test\n",
    "df_data_test = df_data_test[~(df_data_test[\"class\"] == 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "5.0    46.023640\n",
       "7.0    43.091668\n",
       "1.0     7.126455\n",
       "6.0     2.689106\n",
       "2.0     1.069131\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_data_train_k['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_data_train_k) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_labels(df: pd.DataFrame):\n",
    "    df_data = df.copy()\n",
    "    unique_labels = df_data['class'].unique()\n",
    "    unique_labels.sort()\n",
    "\n",
    "    # Mapear os rótulos para inteiros em ordem crescente\n",
    "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Aplicar o mapeamento aos rótulos verdadeiros\n",
    "    labels_int = df_data['class'].map(label_mapping)\n",
    "\n",
    "    # Criar DataFrame com rótulos inteiros\n",
    "    df_mapped = pd.DataFrame({'class': df_data['class'], 'mapped_class': labels_int})\n",
    "    df_data['class'] = df_mapped[\"mapped_class\"]\n",
    "    return df_data, label_mapping\n",
    "\n",
    "def inverse_mapping_labels(df: pd.DataFrame, label_mapping: dict):\n",
    "    df_data = df.copy()\n",
    "    # Inverter o mapeamento original\n",
    "    inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # Aplicar o mapeamento inverso aos rótulos\n",
    "    labels_original = df_data['class'].map(inverse_label_mapping)\n",
    "\n",
    "    # Atualizar o DataFrame com os rótulos originais\n",
    "    df_data['class'] = labels_original\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train_k, label_mapping = mapping_labels(df_data_train_k)\n",
    "#df_data_val, _ = mapping_labels(df_data_val)\n",
    "#df_data_test, _ = mapping_labels(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 0, 2.0: 1, 5.0: 2, 6.0: 3, 7.0: 4}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2    46.023640\n",
       "4    43.091668\n",
       "0     7.126455\n",
       "3     2.689106\n",
       "1     1.069131\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_data_train_k['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_data_train_k) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm_nn_2 = df_data_train_k.drop('class', axis=1)\n",
    "y_train_nn_2 = df_data_train_k['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11519/11519 [==============================] - 13s 1ms/step - loss: 0.0812 - accuracy: 0.9774 - val_loss: 0.0028 - val_accuracy: 0.9996\n",
      "Epoch 2/5\n",
      "  194/11519 [..............................] - ETA: 8s - loss: 0.0012 - accuracy: 0.9998 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11519/11519 [==============================] - 12s 1ms/step - loss: 9.4477e-04 - accuracy: 0.9998 - val_loss: 1.6202e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11519/11519 [==============================] - 12s 1ms/step - loss: 3.7192e-05 - accuracy: 1.0000 - val_loss: 3.7189e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11519/11519 [==============================] - 12s 1ms/step - loss: 1.1678e-06 - accuracy: 1.0000 - val_loss: 3.3040e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11519/11519 [==============================] - 12s 1ms/step - loss: 8.5551e-08 - accuracy: 1.0000 - val_loss: 2.2959e-08 - val_accuracy: 1.0000\n",
      "Acurácia do fold: 100.00%\n",
      "Epoch 1/5\n",
      "11519/11519 [==============================] - 13s 1ms/step - loss: 0.0657 - accuracy: 0.9854 - val_loss: 0.0020 - val_accuracy: 0.9996\n",
      "Epoch 2/5\n",
      "  193/11519 [..............................] - ETA: 8s - loss: 0.0024 - accuracy: 0.9994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11519/11519 [==============================] - 12s 1ms/step - loss: 5.6440e-04 - accuracy: 0.9999 - val_loss: 8.4009e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11519/11519 [==============================] - 11s 950us/step - loss: 2.6815e-05 - accuracy: 1.0000 - val_loss: 5.4222e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11519/11519 [==============================] - 11s 934us/step - loss: 2.1369e-06 - accuracy: 1.0000 - val_loss: 3.6261e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11519/11519 [==============================] - 11s 930us/step - loss: 1.3414e-07 - accuracy: 1.0000 - val_loss: 2.4579e-08 - val_accuracy: 1.0000\n",
      "Acurácia do fold: 100.00%\n",
      "Epoch 1/5\n",
      "11519/11519 [==============================] - 11s 936us/step - loss: 0.0904 - accuracy: 0.9779 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 2/5\n",
      "  203/11519 [..............................] - ETA: 8s - loss: 0.0032 - accuracy: 0.9994 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11519/11519 [==============================] - 11s 933us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.0656e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11519/11519 [==============================] - 11s 927us/step - loss: 9.7609e-05 - accuracy: 1.0000 - val_loss: 2.3101e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11519/11519 [==============================] - 11s 933us/step - loss: 1.3902e-05 - accuracy: 1.0000 - val_loss: 3.4280e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11519/11519 [==============================] - 11s 930us/step - loss: 1.8674e-06 - accuracy: 1.0000 - val_loss: 3.6995e-07 - val_accuracy: 1.0000\n",
      "Acurácia do fold: 100.00%\n",
      "Epoch 1/5\n",
      "11519/11519 [==============================] - 11s 942us/step - loss: 0.0629 - accuracy: 0.9827 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 2/5\n",
      "  280/11519 [..............................] - ETA: 8s - loss: 0.0011 - accuracy: 0.9999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11519/11519 [==============================] - 11s 927us/step - loss: 6.4827e-04 - accuracy: 0.9998 - val_loss: 1.3133e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11519/11519 [==============================] - 11s 922us/step - loss: 3.9038e-05 - accuracy: 1.0000 - val_loss: 3.5050e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11519/11519 [==============================] - 11s 933us/step - loss: 9.6193e-07 - accuracy: 1.0000 - val_loss: 1.2287e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11519/11519 [==============================] - 11s 934us/step - loss: 3.2768e-08 - accuracy: 1.0000 - val_loss: 6.8020e-09 - val_accuracy: 1.0000\n",
      "Acurácia do fold: 100.00%\n",
      "Epoch 1/5\n",
      "11519/11519 [==============================] - 11s 946us/step - loss: 0.0832 - accuracy: 0.9801 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 2/5\n",
      "  192/11519 [..............................] - ETA: 9s - loss: 0.0045 - accuracy: 0.9993"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11519/11519 [==============================] - 11s 935us/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 4.0551e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "11519/11519 [==============================] - 11s 929us/step - loss: 1.1617e-04 - accuracy: 1.0000 - val_loss: 6.0035e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11519/11519 [==============================] - 11s 924us/step - loss: 2.7160e-05 - accuracy: 1.0000 - val_loss: 1.0513e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11519/11519 [==============================] - 11s 935us/step - loss: 7.9422e-06 - accuracy: 1.0000 - val_loss: 2.8959e-06 - val_accuracy: 1.0000\n",
      "Acurácia do fold: 100.00%\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "histories = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_norm_nn_2):\n",
    "    # Divida os dados em treino e validação\n",
    "    X_train_fold, X_val_fold = X_train_norm_nn_2.iloc[train_index], X_train_norm_nn_2.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_nn_2.iloc[train_index], y_train_nn_2.iloc[val_index]\n",
    "\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(8, input_dim=4, activation='relu'))  # Camada de entrada com 8 neurônios e ativação ReLU\n",
    "    # Adicione a camada de saída\n",
    "    model_2.add(Dense(5, activation='softmax'))  # Camada de saída com 5 neurônios (um para cada classe) e ativação Softmax para classificação multiclasse\n",
    "\n",
    "    # Compile o model_2o\n",
    "    model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Defina o checkpoint para salvar os pesos\n",
    "    checkpoint = ModelCheckpoint(\"weights_2.h5\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # Treine o model_2o com conjunto de validação e o checkpoint\n",
    "    history = model_2.fit(X_train_fold, y_train_fold, epochs=5, batch_size=32, validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint], verbose=True)\n",
    "\n",
    "\n",
    "    histories.append(history.history)\n",
    "    # Avalie o modelo\n",
    "    _, accuracy = model_2.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Acurácia do fold: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia média: 100.00%\n",
      "Desvio padrão da acurácia: 0.00%\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f'\\nAcurácia média: {mean_accuracy*100:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Salvar accuracies em um arquivo JSON\n",
    "with open('accuracies_rede_2.json', 'w') as f:\n",
    "    json.dump(accuracies, f)\n",
    "\n",
    "# Salvar histories em um arquivo JSON\n",
    "with open('histories_rede_2.json', 'w') as f:\n",
    "    json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separar as features (X) e os rótulos (y)\n",
    "# X_train_norm_nn_2 = df_data_train.drop('class', axis=1)\n",
    "# y_train_nn_2 = df_data_train['class']\n",
    "# \n",
    "# X_test_norm_nn_2 = df_data_test.drop('class', axis=1)\n",
    "# y_test_nn_2 = df_data_test['class']\n",
    "# \n",
    "# X_val_norm_nn_2 = df_data_val.drop('class', axis=1)\n",
    "# y_val_nn_2 = df_data_val['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32253/32253 [==============================] - 43s 1ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 3.8218e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/2\n",
      "  173/32253 [..............................] - ETA: 28s - loss: 1.3641e-04 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32253/32253 [==============================] - 43s 1ms/step - loss: 8.2413e-05 - accuracy: 1.0000 - val_loss: 2.4104e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17eec439f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_2 = Sequential()\n",
    "# \n",
    "# # Adicione as camadas ocultas\n",
    "# model_2.add(Dense(8, input_dim=4, activation='relu'))  # Camada de entrada com 8 neurônios e ativação ReLU\n",
    "# #model_2.add(Dense(3, activation='relu'))  # Segunda camada oculta com 3 neurônios e ativação ReLU (opcional)\n",
    "# \n",
    "# # Adicione a camada de saída\n",
    "# model_2.add(Dense(5, activation='softmax'))  # Camada de saída com 5 neurônios (um para cada classe) e ativação Softmax para classificação multiclasse\n",
    "# \n",
    "# # Compile o model_2o\n",
    "# model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# \n",
    "# # Defina o checkpoint para salvar os pesos\n",
    "# checkpoint = ModelCheckpoint(\"weights_2.h5\", monitor='val_loss', save_best_only=True)\n",
    "# \n",
    "# # Treine o model_2o com conjunto de validação e o checkpoint\n",
    "# model_2.fit(X_train_norm_nn_2, y_train_nn_2, epochs=2, batch_size=10, validation_data=(X_val_norm_nn_2, y_val_nn_2), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9167/9167 [==============================] - 7s 707us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.973837447156689"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "y_pred = np.squeeze(y_pred)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "accuracy_score(y_test_nn_1.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293320"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all = X_test_norm.copy()\n",
    "df_test_all[\"class\"] = y_pred\n",
    "df_test_all_one = df_test_all[df_test_all[\"class\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = df_test_all_one.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6169/6169 [==============================] - 4s 677us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_all = model_2.predict(X_test_all)\n",
    "y_pred_all = np.argmax(y_pred_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all_one.loc[:, \"class\"] = y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all_one = inverse_mapping_labels(df_test_all_one, label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_all.loc[df_test_all[\"class\"] == 1, \"class\"] = df_test_all_one[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-21 16:48:38</th>\n",
       "      <td>1.256248</td>\n",
       "      <td>0.591633</td>\n",
       "      <td>1.701213</td>\n",
       "      <td>0.123913</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-27 04:46:13</th>\n",
       "      <td>-0.236830</td>\n",
       "      <td>0.645243</td>\n",
       "      <td>-0.190925</td>\n",
       "      <td>0.737439</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-18 07:15:53</th>\n",
       "      <td>-1.297435</td>\n",
       "      <td>-0.427036</td>\n",
       "      <td>-0.805715</td>\n",
       "      <td>-0.805688</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-16 03:04:51</th>\n",
       "      <td>-0.547333</td>\n",
       "      <td>-1.136632</td>\n",
       "      <td>-0.333371</td>\n",
       "      <td>-1.797729</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-15 12:49:09</th>\n",
       "      <td>-0.349048</td>\n",
       "      <td>-1.117220</td>\n",
       "      <td>-0.139313</td>\n",
       "      <td>-1.647358</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-17 18:38:21</th>\n",
       "      <td>1.137084</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>1.021910</td>\n",
       "      <td>0.623915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-19 04:30:13</th>\n",
       "      <td>-1.487571</td>\n",
       "      <td>-0.372468</td>\n",
       "      <td>-0.970286</td>\n",
       "      <td>-0.762578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-17 22:16:32</th>\n",
       "      <td>-1.195370</td>\n",
       "      <td>-0.434045</td>\n",
       "      <td>-0.686572</td>\n",
       "      <td>-0.870438</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 19:32:26</th>\n",
       "      <td>0.612422</td>\n",
       "      <td>0.714572</td>\n",
       "      <td>-1.005371</td>\n",
       "      <td>1.205920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 03:53:01</th>\n",
       "      <td>0.682725</td>\n",
       "      <td>0.675534</td>\n",
       "      <td>-0.979909</td>\n",
       "      <td>1.078246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP  class\n",
       "timestamp                                                           \n",
       "2018-06-21 16:48:38  1.256248  0.591633   1.701213   0.123913      7\n",
       "2017-02-27 04:46:13 -0.236830  0.645243  -0.190925   0.737439      7\n",
       "2014-03-18 07:15:53 -1.297435 -0.427036  -0.805715  -0.805688      5\n",
       "2014-03-16 03:04:51 -0.547333 -1.136632  -0.333371  -1.797729      5\n",
       "2014-03-15 12:49:09 -0.349048 -1.117220  -0.139313  -1.647358      5\n",
       "...                       ...       ...        ...        ...    ...\n",
       "2018-06-17 18:38:21  1.137084  0.638832   1.021910   0.623915      0\n",
       "2014-03-19 04:30:13 -1.487571 -0.372468  -0.970286  -0.762578      0\n",
       "2014-03-17 22:16:32 -1.195370 -0.434045  -0.686572  -0.870438      5\n",
       "2017-08-01 19:32:26  0.612422  0.714572  -1.005371   1.205920      1\n",
       "2017-08-01 03:53:01  0.682725  0.675534  -0.979909   1.078246      0\n",
       "\n",
       "[293320 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973837447156689"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, df_test_all[\"class\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0.0:\n",
      "Precision: 0.9597026440904162\n",
      "Recall: 0.9602633116341178\n",
      "F1-score: 0.9599828959993325\n",
      "\n",
      "Classe 1.0:\n",
      "Precision: 1.0\n",
      "Recall: 0.9995736213757817\n",
      "F1-score: 0.9997867652285165\n",
      "\n",
      "Classe 2.0:\n",
      "Precision: 1.0\n",
      "Recall: 0.9952651515151515\n",
      "F1-score: 0.9976269577598482\n",
      "\n",
      "Classe 5.0:\n",
      "Precision: 0.9955813249296265\n",
      "Recall: 0.9768155809859155\n",
      "F1-score: 0.9861091826023205\n",
      "\n",
      "Classe 6.0:\n",
      "Precision: 0.9992242048099301\n",
      "Recall: 0.9702448210922787\n",
      "F1-score: 0.9845213070896235\n",
      "\n",
      "Classe 7.0:\n",
      "Precision: 0.9607556634490376\n",
      "Recall: 0.9813844165001763\n",
      "F1-score: 0.9709604841663422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, df_test_all[\"class\"].values, average=None)\n",
    "recall = recall_score(y_test, df_test_all[\"class\"].values, average=None)\n",
    "f1 = f1_score(y_test, df_test_all[\"class\"].values, average=None)\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    print(f'Classe {np.unique(y_test)[i]}:')\n",
    "    print(f'Precision: {precision[i]}')\n",
    "    print(f'Recall: {recall[i]}')\n",
    "    print(f'F1-score: {f1[i]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3WPetrobras",
   "language": "python",
   "name": "venv3wpetrobras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
