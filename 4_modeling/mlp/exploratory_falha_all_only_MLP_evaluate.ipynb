{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "from typing import List\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import util\n",
    "from pathlib import Path\n",
    "from sk.replace_column_dataframe import ReplaceColumnDataFrame\n",
    "from sk.norm_standard_scaler import NormStandardScaler\n",
    "import constants.columns_dataframe as const\n",
    "from class_manipulates_path import ManipulatePath\n",
    "from class_preprocessing_refactor import Preprocessing\n",
    "from class_format_data import FormatData\n",
    "util.init()\n",
    "\n",
    "current_path = sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível: []\n",
      "TensorFlow está usando a GPU: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verifique se a GPU está disponível\n",
    "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verifique se o TensorFlow está usando a GPU\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações do TensorFlow relacionadas à GPU:\n",
      "[]\n",
      "TensorFlow está usando a GPU: False\n",
      "Número de GPUs disponíveis: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurações do TensorFlow relacionadas à GPU:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())\n",
    "print(\"Número de GPUs disponíveis:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable(df, column_name, intervalos=None):\n",
    "    \"\"\"\n",
    "    Plota um gráfico de dispersão para uma variável de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "        - df: DataFrame pandas contendo os dados.\n",
    "        - column_name: Nome da coluna que você deseja plotar.\n",
    "        - intervalos: Lista de intervalos para plotar linhas verticais.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(df.index.values, df[column_name].values, color='darkcyan', alpha=0.5)\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel(column_name)\n",
    "    plt.title(f'Gráfico de dispersão para a variável \"{column_name}\"')\n",
    "\n",
    "\n",
    "    # Plotar linhas verticais para cada intervalo\n",
    "    if intervalos:\n",
    "        for intervalo in intervalos:\n",
    "            plt.axvline(x=intervalo, linestyle='--', color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_labels(df: pd.DataFrame):\n",
    "    df_data = df.copy()\n",
    "    unique_labels = df_data['class'].unique()\n",
    "    unique_labels.sort()\n",
    "\n",
    "    # Mapear os rótulos para inteiros em ordem crescente\n",
    "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Aplicar o mapeamento aos rótulos verdadeiros\n",
    "    labels_int = df_data['class'].map(label_mapping)\n",
    "\n",
    "    # Criar DataFrame com rótulos inteiros\n",
    "    df_mapped = pd.DataFrame({'class': df_data['class'], 'mapped_class': labels_int})\n",
    "    df_data['class'] = df_mapped[\"mapped_class\"]\n",
    "    return df_data, label_mapping\n",
    "\n",
    "def inverse_mapping_labels(df: pd.DataFrame, label_mapping: dict):\n",
    "    df_data = df.copy()\n",
    "    # Inverter o mapeamento original\n",
    "    inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # Aplicar o mapeamento inverso aos rótulos\n",
    "    labels_original = df_data['class'].map(inverse_label_mapping)\n",
    "\n",
    "    # Atualizar o DataFrame com os rótulos originais\n",
    "    df_data['class'] = labels_original\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_path = ManipulatePath()\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "\n",
    "format_data = FormatData()\n",
    "\n",
    "path_raw_data = manipulate_path.get_path_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl', 'rb') as file:\n",
    "    loaded_scaler: StandardScaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação com dados desenhados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_parquet(manipulate_path.get_path_preprocessing_draw_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "7    76.090745\n",
       "1    19.606371\n",
       "0     4.302884\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 6.0: 4, 7.0: 5}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 6.0: 4, 7.0: 5}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['class'] = df_preprocessing['class'].replace(7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "5    76.090745\n",
       "1    19.606371\n",
       "0     4.302884\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (X) e os rótulos (y)\n",
    "X = df_preprocessing.drop('class', axis=1)\n",
    "y = df_preprocessing['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:44:36</th>\n",
       "      <td>175.3406</td>\n",
       "      <td>114.8907</td>\n",
       "      <td>96.64524</td>\n",
       "      <td>66.75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:49:17</th>\n",
       "      <td>175.3414</td>\n",
       "      <td>114.8907</td>\n",
       "      <td>96.64524</td>\n",
       "      <td>66.75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:49:18</th>\n",
       "      <td>175.3426</td>\n",
       "      <td>114.8907</td>\n",
       "      <td>96.64524</td>\n",
       "      <td>66.75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:49:19</th>\n",
       "      <td>175.3437</td>\n",
       "      <td>114.8907</td>\n",
       "      <td>96.64524</td>\n",
       "      <td>66.75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-05 20:49:20</th>\n",
       "      <td>175.3449</td>\n",
       "      <td>114.8907</td>\n",
       "      <td>96.64524</td>\n",
       "      <td>66.75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21 11:11:33</th>\n",
       "      <td>211.8868</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91480</td>\n",
       "      <td>65.02185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21 11:11:35</th>\n",
       "      <td>211.8868</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91490</td>\n",
       "      <td>65.02185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21 11:11:36</th>\n",
       "      <td>211.8868</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91500</td>\n",
       "      <td>65.02185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21 11:11:38</th>\n",
       "      <td>211.8869</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91510</td>\n",
       "      <td>65.02185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-21 11:11:40</th>\n",
       "      <td>211.8869</td>\n",
       "      <td>117.8766</td>\n",
       "      <td>122.91520</td>\n",
       "      <td>65.02185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP\n",
       "timestamp                                                    \n",
       "2018-09-05 20:44:36  175.3406  114.8907   96.64524   66.75450\n",
       "2018-09-05 20:49:17  175.3414  114.8907   96.64524   66.75450\n",
       "2018-09-05 20:49:18  175.3426  114.8907   96.64524   66.75450\n",
       "2018-09-05 20:49:19  175.3437  114.8907   96.64524   66.75450\n",
       "2018-09-05 20:49:20  175.3449  114.8907   96.64524   66.75450\n",
       "...                       ...       ...        ...        ...\n",
       "2018-08-21 11:11:33  211.8868  117.8766  122.91480   65.02185\n",
       "2018-08-21 11:11:35  211.8868  117.8766  122.91490   65.02185\n",
       "2018-08-21 11:11:36  211.8868  117.8766  122.91500   65.02185\n",
       "2018-08-21 11:11:38  211.8869  117.8766  122.91510   65.02185\n",
       "2018-08-21 11:11:40  211.8869  117.8766  122.91520   65.02185\n",
       "\n",
       "[1995127 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = loaded_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_load = load_model(os.path.join(Path(os.getcwd()), \"peso_rede_unica.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62348/62348 [==============================] - 42s 673us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014119903144010381"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_1_load.predict(X_norm)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01683162433136606"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0:\n",
      "Precision: 0.05896501596129623\n",
      "Recall: 0.3255404901686702\n",
      "F1-score: 0.09984512519493326\n",
      "\n",
      "Classe 1:\n",
      "Precision: 1.0\n",
      "Recall: 0.0005726381233830643\n",
      "F1-score: 0.0011446207932630892\n",
      "\n",
      "Classe 2:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Classe 3:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Classe 4:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Classe 5:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y, y_pred, average=None)\n",
    "recall = recall_score(y, y_pred, average=None)\n",
    "f1 = f1_score(y, y_pred, average=None)\n",
    "for i in range(len(precision)):\n",
    "    print(f'Classe {i}:')\n",
    "    print(f'Precision: {precision[i]}')\n",
    "    print(f'Recall: {recall[i]}')\n",
    "    print(f'F1-score: {f1[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação com os dados simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_parquet(manipulate_path.get_path_preprocessing_simulated_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "5    55.980035\n",
       "1    40.844868\n",
       "2     2.312167\n",
       "0     0.862930\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 6.0: 4, 7.0: 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing['class'] = df_preprocessing['class'].replace(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (X) e os rótulos (y)\n",
    "X = df_preprocessing.drop('class', axis=1)\n",
    "y = df_preprocessing['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = loaded_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544921/544921 [==============================] - 388s 713us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3756901597246249"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_1_load.predict(X_norm)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0:\n",
      "Precision: 0.006198924133317827\n",
      "Recall: 0.09706060223428788\n",
      "F1-score: 0.01165357484679\n",
      "\n",
      "Classe 1:\n",
      "Precision: 0.5056860010767512\n",
      "Recall: 0.8032740252696354\n",
      "F1-score: 0.6206521535134096\n",
      "\n",
      "Classe 2:\n",
      "Precision: 0.9808749668490312\n",
      "Recall: 0.8898093421597637\n",
      "F1-score: 0.9331255998564246\n",
      "\n",
      "Classe 3:\n",
      "Precision: 0.2785829828337048\n",
      "Recall: 0.046771138422515415\n",
      "F1-score: 0.08009514803109836\n",
      "\n",
      "Classe 4:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Classe 5:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y, y_pred, average=None)\n",
    "recall = recall_score(y, y_pred, average=None)\n",
    "f1 = f1_score(y, y_pred, average=None)\n",
    "for i in range(len(precision)):\n",
    "    print(f'Classe {np.unique(y_pred)[i]}:')\n",
    "    print(f'Precision: {precision[i]}')\n",
    "    print(f'Recall: {recall[i]}')\n",
    "    print(f'F1-score: {f1[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação com todos os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_parquet(manipulate_path.get_path_preprocessing_real_data_all_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0.0    32.679781\n",
       "5.0    30.983203\n",
       "7.0    29.009351\n",
       "1.0     4.797527\n",
       "6.0     1.810310\n",
       "2.0     0.719828\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing, label_mapping_2 = mapping_labels(df_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    32.679781\n",
       "3    30.983203\n",
       "5    29.009351\n",
       "1     4.797527\n",
       "4     1.810310\n",
       "2     0.719828\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30555/30555 [==============================] - 23s 749us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9790617683968936"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar as features (X) e os rótulos (y)\n",
    "X = df_preprocessing.drop('class', axis=1)\n",
    "y = df_preprocessing['class']\n",
    "\n",
    "X_norm = loaded_scaler.transform(X)\n",
    "\n",
    "y_pred = model_1_load.predict(X_norm)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy_score(y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3WPetrobras",
   "language": "python",
   "name": "venv3wpetrobras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
