{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import dill\n",
    "from typing import List\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import util\n",
    "from pathlib import Path\n",
    "from sk.replace_column_dataframe import ReplaceColumnDataFrame\n",
    "from sk.norm_standard_scaler import NormStandardScaler\n",
    "import constants.columns_dataframe as const\n",
    "from class_manipulates_path import ManipulatePath\n",
    "from class_preprocessing_refactor import Preprocessing\n",
    "from class_format_data import FormatData\n",
    "util.init()\n",
    "\n",
    "current_path = sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível: []\n",
      "TensorFlow está usando a GPU: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verifique se a GPU está disponível\n",
    "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verifique se o TensorFlow está usando a GPU\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações do TensorFlow relacionadas à GPU:\n",
      "[]\n",
      "TensorFlow está usando a GPU: False\n",
      "Número de GPUs disponíveis: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Configurações do TensorFlow relacionadas à GPU:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow está usando a GPU:\", tf.test.is_built_with_cuda())\n",
    "print(\"Número de GPUs disponíveis:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable(df, column_name, intervalos=None):\n",
    "    \"\"\"\n",
    "    Plota um gráfico de dispersão para uma variável de um DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "        - df: DataFrame pandas contendo os dados.\n",
    "        - column_name: Nome da coluna que você deseja plotar.\n",
    "        - intervalos: Lista de intervalos para plotar linhas verticais.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(df.index.values, df[column_name].values, color='darkcyan', alpha=0.5)\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel(column_name)\n",
    "    plt.title(f'Gráfico de dispersão para a variável \"{column_name}\"')\n",
    "\n",
    "\n",
    "    # Plotar linhas verticais para cada intervalo\n",
    "    if intervalos:\n",
    "        for intervalo in intervalos:\n",
    "            plt.axvline(x=intervalo, linestyle='--', color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_labels(df: pd.DataFrame):\n",
    "    df_data = df.copy()\n",
    "    unique_labels = df_data['class'].unique()\n",
    "    unique_labels.sort()\n",
    "\n",
    "    # Mapear os rótulos para inteiros em ordem crescente\n",
    "    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Aplicar o mapeamento aos rótulos verdadeiros\n",
    "    labels_int = df_data['class'].map(label_mapping)\n",
    "\n",
    "    # Criar DataFrame com rótulos inteiros\n",
    "    df_mapped = pd.DataFrame({'class': df_data['class'], 'mapped_class': labels_int})\n",
    "    df_data['class'] = df_mapped[\"mapped_class\"]\n",
    "    return df_data, label_mapping\n",
    "\n",
    "def inverse_mapping_labels(df: pd.DataFrame, label_mapping: dict):\n",
    "    df_data = df.copy()\n",
    "    # Inverter o mapeamento original\n",
    "    inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    # Aplicar o mapeamento inverso aos rótulos\n",
    "    labels_original = df_data['class'].map(inverse_label_mapping)\n",
    "\n",
    "    # Atualizar o DataFrame com os rótulos originais\n",
    "    df_data['class'] = labels_original\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulate_path = ManipulatePath()\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "\n",
    "format_data = FormatData()\n",
    "\n",
    "path_raw_data = manipulate_path.get_path_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing = pd.read_parquet(manipulate_path.get_path_preprocessing_real_data_all_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0.0    32.679781\n",
       "5.0    30.983203\n",
       "7.0    29.009351\n",
       "1.0     4.797527\n",
       "6.0     1.810310\n",
       "2.0     0.719828\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é possível ver que tem poquíssimas classes normais!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessing, label_mapping = mapping_labels(df_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0, 1.0: 1, 2.0: 2, 5.0: 3, 6.0: 4, 7.0: 5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    32.679781\n",
       "3    30.983203\n",
       "5    29.009351\n",
       "1     4.797527\n",
       "4     1.810310\n",
       "2     0.719828\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contagem_classes = df_preprocessing['class'].value_counts()\n",
    "\n",
    "# Calcular a porcentagem de cada classe\n",
    "porcentagem_classes_real = contagem_classes / len(df_preprocessing) * 100\n",
    "porcentagem_classes_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar as features (X) e os rótulos (y)\n",
    "X = df_preprocessing.drop('class', axis=1)\n",
    "y = df_preprocessing['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:03</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397031.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:04</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397031.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:05</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397032.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:06</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397033.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-24 09:33:07</th>\n",
       "      <td>18433410.0</td>\n",
       "      <td>116.8718</td>\n",
       "      <td>9397033.0</td>\n",
       "      <td>74.80031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:56</th>\n",
       "      <td>8489354.0</td>\n",
       "      <td>109.7213</td>\n",
       "      <td>1496222.0</td>\n",
       "      <td>73.38219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:57</th>\n",
       "      <td>8489349.0</td>\n",
       "      <td>109.7212</td>\n",
       "      <td>1495828.0</td>\n",
       "      <td>73.38310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:58</th>\n",
       "      <td>8489344.0</td>\n",
       "      <td>109.7210</td>\n",
       "      <td>1495433.0</td>\n",
       "      <td>73.38401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 14:59:59</th>\n",
       "      <td>8489338.0</td>\n",
       "      <td>109.7209</td>\n",
       "      <td>1495039.0</td>\n",
       "      <td>73.38493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 15:00:00</th>\n",
       "      <td>8489333.0</td>\n",
       "      <td>109.7207</td>\n",
       "      <td>1494645.0</td>\n",
       "      <td>73.38583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977733 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          P-TPT     T-TPT  P-MON-CKP  T-JUS-CKP\n",
       "timestamp                                                      \n",
       "2014-01-24 09:33:03  18433410.0  116.8718  9397031.0   74.80031\n",
       "2014-01-24 09:33:04  18433410.0  116.8718  9397031.0   74.80031\n",
       "2014-01-24 09:33:05  18433410.0  116.8718  9397032.0   74.80031\n",
       "2014-01-24 09:33:06  18433410.0  116.8718  9397033.0   74.80031\n",
       "2014-01-24 09:33:07  18433410.0  116.8718  9397033.0   74.80031\n",
       "...                         ...       ...        ...        ...\n",
       "2019-04-03 14:59:56   8489354.0  109.7213  1496222.0   73.38219\n",
       "2019-04-03 14:59:57   8489349.0  109.7212  1495828.0   73.38310\n",
       "2019-04-03 14:59:58   8489344.0  109.7210  1495433.0   73.38401\n",
       "2019-04-03 14:59:59   8489338.0  109.7209  1495039.0   73.38493\n",
       "2019-04-03 15:00:00   8489333.0  109.7207  1494645.0   73.38583\n",
       "\n",
       "[977733 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_k, X_test, y_train_k, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_k, y_train_k, test_size=0.2, stratify=y_train_k, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = NormStandardScaler(X_train.columns)\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "X_train_k_norm = scaler.transform(X_train_k)\n",
    "\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('scaler.pkl', 'wb') as file:\n",
    "#     pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.3243 - accuracy: 0.8746 - val_loss: 0.1911 - val_accuracy: 0.9256\n",
      "Epoch 2/100\n",
      " 135/8556 [..............................] - ETA: 9s - loss: 0.1964 - accuracy: 0.9243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1718 - accuracy: 0.9344 - val_loss: 0.1528 - val_accuracy: 0.9431\n",
      "Epoch 3/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1371 - accuracy: 0.9444 - val_loss: 0.1285 - val_accuracy: 0.9502\n",
      "Epoch 4/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1190 - accuracy: 0.9513 - val_loss: 0.1085 - val_accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1096 - accuracy: 0.9561 - val_loss: 0.1051 - val_accuracy: 0.9555\n",
      "Epoch 6/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.1025 - accuracy: 0.9589 - val_loss: 0.1010 - val_accuracy: 0.9606\n",
      "Epoch 7/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0976 - accuracy: 0.9607 - val_loss: 0.1043 - val_accuracy: 0.9588\n",
      "Epoch 8/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0943 - accuracy: 0.9619 - val_loss: 0.0934 - val_accuracy: 0.9579\n",
      "Epoch 9/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0923 - accuracy: 0.9626 - val_loss: 0.0873 - val_accuracy: 0.9664\n",
      "Epoch 10/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0905 - accuracy: 0.9633 - val_loss: 0.0829 - val_accuracy: 0.9655\n",
      "Epoch 11/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0890 - accuracy: 0.9638 - val_loss: 0.1152 - val_accuracy: 0.9603\n",
      "Epoch 12/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0883 - accuracy: 0.9638 - val_loss: 0.0780 - val_accuracy: 0.9678\n",
      "Epoch 13/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0864 - accuracy: 0.9647 - val_loss: 0.0803 - val_accuracy: 0.9668\n",
      "Epoch 14/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0870 - accuracy: 0.9643 - val_loss: 0.0804 - val_accuracy: 0.9669\n",
      "Epoch 15/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0844 - accuracy: 0.9654 - val_loss: 0.0750 - val_accuracy: 0.9702\n",
      "Epoch 16/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0838 - accuracy: 0.9654 - val_loss: 0.0965 - val_accuracy: 0.9600\n",
      "Epoch 17/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0829 - accuracy: 0.9660 - val_loss: 0.0830 - val_accuracy: 0.9672\n",
      "Epoch 18/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0819 - accuracy: 0.9660 - val_loss: 0.0921 - val_accuracy: 0.9612\n",
      "Epoch 19/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0826 - accuracy: 0.9660 - val_loss: 0.0934 - val_accuracy: 0.9601\n",
      "Epoch 20/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0804 - accuracy: 0.9665 - val_loss: 0.0711 - val_accuracy: 0.9709\n",
      "Epoch 21/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0797 - accuracy: 0.9668 - val_loss: 0.0961 - val_accuracy: 0.9607\n",
      "Epoch 22/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0795 - accuracy: 0.9669 - val_loss: 0.0866 - val_accuracy: 0.9625\n",
      "Epoch 23/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0784 - accuracy: 0.9675 - val_loss: 0.0708 - val_accuracy: 0.9710\n",
      "Epoch 24/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0769 - accuracy: 0.9678 - val_loss: 0.0745 - val_accuracy: 0.9682\n",
      "Epoch 25/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0776 - accuracy: 0.9677 - val_loss: 0.0789 - val_accuracy: 0.9678\n",
      "Epoch 26/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0764 - accuracy: 0.9680 - val_loss: 0.0828 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0752 - accuracy: 0.9684 - val_loss: 0.0661 - val_accuracy: 0.9733\n",
      "Epoch 28/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0746 - accuracy: 0.9685 - val_loss: 0.0717 - val_accuracy: 0.9712\n",
      "Epoch 29/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0746 - accuracy: 0.9689 - val_loss: 0.0791 - val_accuracy: 0.9688\n",
      "Epoch 30/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0745 - accuracy: 0.9686 - val_loss: 0.0842 - val_accuracy: 0.9726\n",
      "Epoch 31/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0812 - accuracy: 0.9659 - val_loss: 0.0812 - val_accuracy: 0.9624\n",
      "Epoch 32/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0780 - accuracy: 0.9686 - val_loss: 0.0756 - val_accuracy: 0.9677\n",
      "Epoch 33/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0768 - accuracy: 0.9691 - val_loss: 0.0667 - val_accuracy: 0.9757\n",
      "Epoch 34/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0760 - accuracy: 0.9697 - val_loss: 0.0708 - val_accuracy: 0.9725\n",
      "Epoch 35/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0768 - accuracy: 0.9693 - val_loss: 0.0905 - val_accuracy: 0.9677\n",
      "Epoch 36/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0749 - accuracy: 0.9700 - val_loss: 0.0698 - val_accuracy: 0.9699\n",
      "Epoch 37/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0752 - accuracy: 0.9700 - val_loss: 0.1008 - val_accuracy: 0.9632\n",
      "Epoch 38/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0738 - accuracy: 0.9704 - val_loss: 0.0705 - val_accuracy: 0.9719\n",
      "Epoch 39/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0713 - accuracy: 0.9707 - val_loss: 0.0670 - val_accuracy: 0.9721\n",
      "Epoch 40/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0691 - accuracy: 0.9711 - val_loss: 0.0631 - val_accuracy: 0.9737\n",
      "Epoch 41/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0673 - accuracy: 0.9717 - val_loss: 0.0650 - val_accuracy: 0.9707\n",
      "Epoch 42/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0684 - accuracy: 0.9713 - val_loss: 0.0663 - val_accuracy: 0.9738\n",
      "Epoch 43/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0668 - accuracy: 0.9720 - val_loss: 0.0735 - val_accuracy: 0.9672\n",
      "Epoch 44/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0662 - accuracy: 0.9723 - val_loss: 0.0633 - val_accuracy: 0.9728\n",
      "Epoch 45/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0658 - accuracy: 0.9727 - val_loss: 0.0855 - val_accuracy: 0.9642\n",
      "Epoch 46/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0643 - accuracy: 0.9731 - val_loss: 0.0788 - val_accuracy: 0.9680\n",
      "Epoch 47/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0659 - accuracy: 0.9729 - val_loss: 0.0593 - val_accuracy: 0.9767\n",
      "Epoch 48/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0635 - accuracy: 0.9736 - val_loss: 0.0552 - val_accuracy: 0.9772\n",
      "Epoch 49/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0623 - accuracy: 0.9740 - val_loss: 0.0538 - val_accuracy: 0.9768\n",
      "Epoch 50/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0632 - accuracy: 0.9740 - val_loss: 0.0563 - val_accuracy: 0.9754\n",
      "Epoch 51/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0609 - accuracy: 0.9747 - val_loss: 0.0738 - val_accuracy: 0.9674\n",
      "Epoch 52/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0604 - accuracy: 0.9753 - val_loss: 0.1056 - val_accuracy: 0.9665\n",
      "Epoch 53/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0614 - accuracy: 0.9747 - val_loss: 0.0594 - val_accuracy: 0.9749\n",
      "Epoch 54/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0600 - accuracy: 0.9755 - val_loss: 0.0528 - val_accuracy: 0.9790\n",
      "Epoch 55/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0584 - accuracy: 0.9761 - val_loss: 0.0607 - val_accuracy: 0.9739\n",
      "Epoch 56/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0579 - accuracy: 0.9761 - val_loss: 0.0605 - val_accuracy: 0.9744\n",
      "Epoch 57/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0587 - accuracy: 0.9763 - val_loss: 0.0763 - val_accuracy: 0.9707\n",
      "Epoch 58/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0574 - accuracy: 0.9766 - val_loss: 0.0547 - val_accuracy: 0.9773\n",
      "Epoch 59/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0563 - accuracy: 0.9770 - val_loss: 0.0543 - val_accuracy: 0.9792\n",
      "Epoch 60/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0568 - accuracy: 0.9770 - val_loss: 0.0632 - val_accuracy: 0.9775\n",
      "Epoch 61/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0556 - accuracy: 0.9773 - val_loss: 0.0531 - val_accuracy: 0.9795\n",
      "Epoch 62/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0557 - accuracy: 0.9772 - val_loss: 0.0491 - val_accuracy: 0.9812\n",
      "Epoch 63/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0542 - accuracy: 0.9779 - val_loss: 0.0519 - val_accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0534 - accuracy: 0.9782 - val_loss: 0.0503 - val_accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0531 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9809\n",
      "Epoch 66/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0523 - accuracy: 0.9785 - val_loss: 0.0477 - val_accuracy: 0.9817\n",
      "Epoch 67/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0521 - accuracy: 0.9786 - val_loss: 0.0454 - val_accuracy: 0.9814\n",
      "Epoch 68/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0522 - accuracy: 0.9787 - val_loss: 0.0481 - val_accuracy: 0.9799\n",
      "Epoch 69/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0520 - accuracy: 0.9788 - val_loss: 0.0495 - val_accuracy: 0.9808\n",
      "Epoch 70/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0557 - accuracy: 0.9773 - val_loss: 0.0652 - val_accuracy: 0.9757\n",
      "Epoch 71/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0630 - accuracy: 0.9757 - val_loss: 0.0569 - val_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 0.0605 - val_accuracy: 0.9787\n",
      "Epoch 73/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0571 - accuracy: 0.9778 - val_loss: 0.0516 - val_accuracy: 0.9806\n",
      "Epoch 74/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0553 - accuracy: 0.9782 - val_loss: 0.0640 - val_accuracy: 0.9741\n",
      "Epoch 75/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0554 - accuracy: 0.9782 - val_loss: 0.0543 - val_accuracy: 0.9787\n",
      "Epoch 76/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0535 - accuracy: 0.9789 - val_loss: 0.0508 - val_accuracy: 0.9813\n",
      "Epoch 77/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0529 - accuracy: 0.9792 - val_loss: 0.0445 - val_accuracy: 0.9832\n",
      "Epoch 78/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0528 - accuracy: 0.9792 - val_loss: 0.0469 - val_accuracy: 0.9827\n",
      "Epoch 79/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0521 - accuracy: 0.9794 - val_loss: 0.0649 - val_accuracy: 0.9744\n",
      "Epoch 80/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0532 - accuracy: 0.9789 - val_loss: 0.0595 - val_accuracy: 0.9771\n",
      "Epoch 81/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0516 - accuracy: 0.9796 - val_loss: 0.0467 - val_accuracy: 0.9810\n",
      "Epoch 82/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0514 - accuracy: 0.9795 - val_loss: 0.0545 - val_accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0512 - accuracy: 0.9797 - val_loss: 0.0651 - val_accuracy: 0.9738\n",
      "Epoch 84/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0514 - accuracy: 0.9795 - val_loss: 0.0549 - val_accuracy: 0.9782\n",
      "Epoch 85/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0509 - accuracy: 0.9799 - val_loss: 0.0435 - val_accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0504 - accuracy: 0.9798 - val_loss: 0.0457 - val_accuracy: 0.9813\n",
      "Epoch 87/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0500 - accuracy: 0.9798 - val_loss: 0.0499 - val_accuracy: 0.9809\n",
      "Epoch 88/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0495 - accuracy: 0.9804 - val_loss: 0.0432 - val_accuracy: 0.9831\n",
      "Epoch 89/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0498 - accuracy: 0.9802 - val_loss: 0.0719 - val_accuracy: 0.9703\n",
      "Epoch 90/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0495 - accuracy: 0.9803 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
      "Epoch 91/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0507 - accuracy: 0.9800 - val_loss: 0.0527 - val_accuracy: 0.9794\n",
      "Epoch 92/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0489 - accuracy: 0.9806 - val_loss: 0.0417 - val_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0488 - accuracy: 0.9806 - val_loss: 0.0432 - val_accuracy: 0.9835\n",
      "Epoch 94/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0482 - accuracy: 0.9808 - val_loss: 0.0462 - val_accuracy: 0.9807\n",
      "Epoch 95/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0483 - accuracy: 0.9804 - val_loss: 0.0471 - val_accuracy: 0.9827\n",
      "Epoch 96/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0478 - accuracy: 0.9808 - val_loss: 0.0416 - val_accuracy: 0.9853\n",
      "Epoch 97/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0478 - accuracy: 0.9809 - val_loss: 0.0460 - val_accuracy: 0.9824\n",
      "Epoch 98/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0474 - accuracy: 0.9809 - val_loss: 0.0422 - val_accuracy: 0.9836\n",
      "Epoch 99/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0468 - accuracy: 0.9811 - val_loss: 0.0460 - val_accuracy: 0.9817\n",
      "Epoch 100/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0467 - accuracy: 0.9812 - val_loss: 0.0399 - val_accuracy: 0.9845\n",
      "Acurácia do fold: 98.45%\n",
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.3302 - accuracy: 0.8683 - val_loss: 0.2084 - val_accuracy: 0.9094\n",
      "Epoch 2/100\n",
      " 169/8556 [..............................] - ETA: 7s - loss: 0.1883 - accuracy: 0.9271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1639 - accuracy: 0.9373 - val_loss: 0.1446 - val_accuracy: 0.9526\n",
      "Epoch 3/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1360 - accuracy: 0.9476 - val_loss: 0.1269 - val_accuracy: 0.9490\n",
      "Epoch 4/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.1241 - accuracy: 0.9511 - val_loss: 0.1290 - val_accuracy: 0.9455\n",
      "Epoch 5/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1175 - accuracy: 0.9531 - val_loss: 0.1188 - val_accuracy: 0.9520\n",
      "Epoch 6/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.1131 - accuracy: 0.9539 - val_loss: 0.1041 - val_accuracy: 0.9558\n",
      "Epoch 7/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1107 - accuracy: 0.9542 - val_loss: 0.1188 - val_accuracy: 0.9475\n",
      "Epoch 8/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.1071 - accuracy: 0.9556 - val_loss: 0.1116 - val_accuracy: 0.9524\n",
      "Epoch 9/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.1055 - accuracy: 0.9555 - val_loss: 0.1269 - val_accuracy: 0.9478\n",
      "Epoch 10/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1026 - accuracy: 0.9564 - val_loss: 0.0962 - val_accuracy: 0.9573\n",
      "Epoch 11/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0993 - accuracy: 0.9569 - val_loss: 0.0948 - val_accuracy: 0.9607\n",
      "Epoch 12/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0959 - accuracy: 0.9582 - val_loss: 0.1134 - val_accuracy: 0.9542\n",
      "Epoch 13/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0935 - accuracy: 0.9616 - val_loss: 0.0995 - val_accuracy: 0.9616\n",
      "Epoch 14/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0919 - accuracy: 0.9630 - val_loss: 0.0844 - val_accuracy: 0.9674\n",
      "Epoch 15/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0917 - accuracy: 0.9633 - val_loss: 0.0834 - val_accuracy: 0.9654\n",
      "Epoch 16/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0907 - accuracy: 0.9638 - val_loss: 0.0898 - val_accuracy: 0.9678\n",
      "Epoch 17/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0902 - accuracy: 0.9639 - val_loss: 0.0955 - val_accuracy: 0.9649\n",
      "Epoch 18/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0888 - accuracy: 0.9645 - val_loss: 0.1063 - val_accuracy: 0.9573\n",
      "Epoch 19/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0882 - accuracy: 0.9651 - val_loss: 0.0838 - val_accuracy: 0.9681\n",
      "Epoch 20/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0881 - accuracy: 0.9651 - val_loss: 0.0864 - val_accuracy: 0.9662\n",
      "Epoch 21/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0867 - accuracy: 0.9659 - val_loss: 0.0859 - val_accuracy: 0.9658\n",
      "Epoch 22/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0867 - accuracy: 0.9656 - val_loss: 0.0875 - val_accuracy: 0.9608\n",
      "Epoch 23/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0852 - accuracy: 0.9664 - val_loss: 0.0967 - val_accuracy: 0.9608\n",
      "Epoch 24/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0847 - accuracy: 0.9664 - val_loss: 0.0790 - val_accuracy: 0.9681\n",
      "Epoch 25/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0836 - accuracy: 0.9669 - val_loss: 0.0819 - val_accuracy: 0.9684\n",
      "Epoch 26/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0817 - accuracy: 0.9676 - val_loss: 0.0802 - val_accuracy: 0.9696\n",
      "Epoch 27/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0806 - accuracy: 0.9681 - val_loss: 0.0790 - val_accuracy: 0.9702\n",
      "Epoch 28/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0794 - accuracy: 0.9683 - val_loss: 0.0781 - val_accuracy: 0.9685\n",
      "Epoch 29/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.0724 - val_accuracy: 0.9721\n",
      "Epoch 30/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0772 - accuracy: 0.9690 - val_loss: 0.0715 - val_accuracy: 0.9732\n",
      "Epoch 31/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0756 - accuracy: 0.9698 - val_loss: 0.0828 - val_accuracy: 0.9616\n",
      "Epoch 32/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0754 - accuracy: 0.9699 - val_loss: 0.0704 - val_accuracy: 0.9731\n",
      "Epoch 33/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0738 - accuracy: 0.9706 - val_loss: 0.0705 - val_accuracy: 0.9725\n",
      "Epoch 34/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0730 - accuracy: 0.9709 - val_loss: 0.0875 - val_accuracy: 0.9633\n",
      "Epoch 35/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0722 - accuracy: 0.9710 - val_loss: 0.0710 - val_accuracy: 0.9703\n",
      "Epoch 36/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0713 - accuracy: 0.9714 - val_loss: 0.0667 - val_accuracy: 0.9720\n",
      "Epoch 37/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.0727 - val_accuracy: 0.9700\n",
      "Epoch 38/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0695 - accuracy: 0.9720 - val_loss: 0.0722 - val_accuracy: 0.9707\n",
      "Epoch 39/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0688 - accuracy: 0.9722 - val_loss: 0.0642 - val_accuracy: 0.9746\n",
      "Epoch 40/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0680 - accuracy: 0.9724 - val_loss: 0.0704 - val_accuracy: 0.9729\n",
      "Epoch 41/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0671 - accuracy: 0.9730 - val_loss: 0.0810 - val_accuracy: 0.9667\n",
      "Epoch 42/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0669 - accuracy: 0.9728 - val_loss: 0.0816 - val_accuracy: 0.9682\n",
      "Epoch 43/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0666 - accuracy: 0.9729 - val_loss: 0.0638 - val_accuracy: 0.9759\n",
      "Epoch 44/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0660 - accuracy: 0.9730 - val_loss: 0.0637 - val_accuracy: 0.9749\n",
      "Epoch 45/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0651 - accuracy: 0.9734 - val_loss: 0.0676 - val_accuracy: 0.9737\n",
      "Epoch 46/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0639 - accuracy: 0.9734 - val_loss: 0.0689 - val_accuracy: 0.9699\n",
      "Epoch 47/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0639 - accuracy: 0.9735 - val_loss: 0.0707 - val_accuracy: 0.9714\n",
      "Epoch 48/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0634 - accuracy: 0.9739 - val_loss: 0.0580 - val_accuracy: 0.9738\n",
      "Epoch 49/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0629 - accuracy: 0.9737 - val_loss: 0.0654 - val_accuracy: 0.9731\n",
      "Epoch 50/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0630 - accuracy: 0.9742 - val_loss: 0.0576 - val_accuracy: 0.9774\n",
      "Epoch 51/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0627 - accuracy: 0.9742 - val_loss: 0.0605 - val_accuracy: 0.9757\n",
      "Epoch 52/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0613 - accuracy: 0.9747 - val_loss: 0.0594 - val_accuracy: 0.9764\n",
      "Epoch 53/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0608 - accuracy: 0.9747 - val_loss: 0.0594 - val_accuracy: 0.9736\n",
      "Epoch 54/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0607 - accuracy: 0.9749 - val_loss: 0.0560 - val_accuracy: 0.9771\n",
      "Epoch 55/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0606 - accuracy: 0.9747 - val_loss: 0.0540 - val_accuracy: 0.9766\n",
      "Epoch 56/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0598 - accuracy: 0.9751 - val_loss: 0.0695 - val_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0597 - accuracy: 0.9754 - val_loss: 0.0514 - val_accuracy: 0.9782\n",
      "Epoch 58/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0594 - accuracy: 0.9752 - val_loss: 0.0639 - val_accuracy: 0.9748\n",
      "Epoch 59/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0589 - accuracy: 0.9756 - val_loss: 0.0527 - val_accuracy: 0.9782\n",
      "Epoch 60/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0586 - accuracy: 0.9760 - val_loss: 0.0577 - val_accuracy: 0.9765\n",
      "Epoch 61/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0581 - accuracy: 0.9759 - val_loss: 0.0567 - val_accuracy: 0.9757\n",
      "Epoch 62/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0576 - accuracy: 0.9762 - val_loss: 0.0566 - val_accuracy: 0.9770\n",
      "Epoch 63/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0573 - accuracy: 0.9761 - val_loss: 0.0603 - val_accuracy: 0.9733\n",
      "Epoch 64/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0572 - accuracy: 0.9762 - val_loss: 0.0570 - val_accuracy: 0.9765\n",
      "Epoch 65/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0574 - accuracy: 0.9761 - val_loss: 0.0492 - val_accuracy: 0.9792\n",
      "Epoch 66/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0566 - accuracy: 0.9763 - val_loss: 0.0524 - val_accuracy: 0.9789\n",
      "Epoch 67/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0563 - accuracy: 0.9766 - val_loss: 0.0520 - val_accuracy: 0.9770\n",
      "Epoch 68/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0563 - accuracy: 0.9767 - val_loss: 0.0638 - val_accuracy: 0.9711\n",
      "Epoch 69/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0552 - accuracy: 0.9769 - val_loss: 0.0578 - val_accuracy: 0.9761\n",
      "Epoch 70/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0557 - accuracy: 0.9768 - val_loss: 0.0555 - val_accuracy: 0.9760\n",
      "Epoch 71/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0549 - accuracy: 0.9769 - val_loss: 0.0554 - val_accuracy: 0.9743\n",
      "Epoch 72/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0547 - accuracy: 0.9771 - val_loss: 0.0591 - val_accuracy: 0.9749\n",
      "Epoch 73/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0547 - accuracy: 0.9770 - val_loss: 0.0492 - val_accuracy: 0.9794\n",
      "Epoch 74/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0544 - accuracy: 0.9771 - val_loss: 0.0522 - val_accuracy: 0.9776\n",
      "Epoch 75/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0541 - accuracy: 0.9772 - val_loss: 0.0525 - val_accuracy: 0.9772\n",
      "Epoch 76/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0540 - accuracy: 0.9771 - val_loss: 0.0572 - val_accuracy: 0.9730\n",
      "Epoch 77/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0534 - accuracy: 0.9774 - val_loss: 0.0478 - val_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0531 - accuracy: 0.9778 - val_loss: 0.0484 - val_accuracy: 0.9791\n",
      "Epoch 79/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0533 - accuracy: 0.9777 - val_loss: 0.0521 - val_accuracy: 0.9765\n",
      "Epoch 80/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0526 - accuracy: 0.9778 - val_loss: 0.0600 - val_accuracy: 0.9744\n",
      "Epoch 81/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0525 - accuracy: 0.9779 - val_loss: 0.0533 - val_accuracy: 0.9784\n",
      "Epoch 82/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0517 - accuracy: 0.9782 - val_loss: 0.0499 - val_accuracy: 0.9775\n",
      "Epoch 83/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0518 - accuracy: 0.9778 - val_loss: 0.0703 - val_accuracy: 0.9683\n",
      "Epoch 84/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0519 - accuracy: 0.9781 - val_loss: 0.0600 - val_accuracy: 0.9754\n",
      "Epoch 85/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0510 - accuracy: 0.9783 - val_loss: 0.0779 - val_accuracy: 0.9686\n",
      "Epoch 86/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0510 - accuracy: 0.9782 - val_loss: 0.0530 - val_accuracy: 0.9760\n",
      "Epoch 87/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0514 - accuracy: 0.9782 - val_loss: 0.0440 - val_accuracy: 0.9808\n",
      "Epoch 88/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0507 - accuracy: 0.9785 - val_loss: 0.0446 - val_accuracy: 0.9816\n",
      "Epoch 89/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0507 - accuracy: 0.9786 - val_loss: 0.0560 - val_accuracy: 0.9740\n",
      "Epoch 90/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0499 - accuracy: 0.9788 - val_loss: 0.0482 - val_accuracy: 0.9802\n",
      "Epoch 91/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0513 - accuracy: 0.9783 - val_loss: 0.0595 - val_accuracy: 0.9758\n",
      "Epoch 92/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0519 - accuracy: 0.9782 - val_loss: 0.0525 - val_accuracy: 0.9774\n",
      "Epoch 93/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0500 - accuracy: 0.9790 - val_loss: 0.0511 - val_accuracy: 0.9784\n",
      "Epoch 94/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0500 - accuracy: 0.9790 - val_loss: 0.0563 - val_accuracy: 0.9763\n",
      "Epoch 95/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0496 - accuracy: 0.9790 - val_loss: 0.0509 - val_accuracy: 0.9780\n",
      "Epoch 96/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0500 - accuracy: 0.9792 - val_loss: 0.0481 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0487 - accuracy: 0.9793 - val_loss: 0.0436 - val_accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0484 - accuracy: 0.9794 - val_loss: 0.0436 - val_accuracy: 0.9820\n",
      "Epoch 99/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0489 - accuracy: 0.9794 - val_loss: 0.0545 - val_accuracy: 0.9750\n",
      "Epoch 100/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0477 - accuracy: 0.9797 - val_loss: 0.0449 - val_accuracy: 0.9803\n",
      "Acurácia do fold: 98.03%\n",
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.3212 - accuracy: 0.8716 - val_loss: 0.1780 - val_accuracy: 0.9322\n",
      "Epoch 2/100\n",
      " 128/8556 [..............................] - ETA: 10s - loss: 0.1887 - accuracy: 0.9281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1548 - accuracy: 0.9376 - val_loss: 0.1368 - val_accuracy: 0.9555\n",
      "Epoch 3/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1302 - accuracy: 0.9466 - val_loss: 0.1173 - val_accuracy: 0.9497\n",
      "Epoch 4/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1192 - accuracy: 0.9503 - val_loss: 0.1179 - val_accuracy: 0.9455\n",
      "Epoch 5/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1127 - accuracy: 0.9530 - val_loss: 0.1274 - val_accuracy: 0.9523\n",
      "Epoch 6/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1083 - accuracy: 0.9550 - val_loss: 0.1014 - val_accuracy: 0.9584\n",
      "Epoch 7/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1047 - accuracy: 0.9565 - val_loss: 0.1084 - val_accuracy: 0.9525\n",
      "Epoch 8/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1002 - accuracy: 0.9580 - val_loss: 0.0976 - val_accuracy: 0.9578\n",
      "Epoch 9/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0968 - accuracy: 0.9591 - val_loss: 0.0938 - val_accuracy: 0.9585\n",
      "Epoch 10/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0942 - accuracy: 0.9603 - val_loss: 0.0933 - val_accuracy: 0.9637\n",
      "Epoch 11/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0921 - accuracy: 0.9613 - val_loss: 0.0906 - val_accuracy: 0.9642\n",
      "Epoch 12/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0896 - accuracy: 0.9622 - val_loss: 0.0810 - val_accuracy: 0.9651\n",
      "Epoch 13/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0884 - accuracy: 0.9628 - val_loss: 0.1121 - val_accuracy: 0.9596\n",
      "Epoch 14/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0875 - accuracy: 0.9636 - val_loss: 0.0895 - val_accuracy: 0.9619\n",
      "Epoch 15/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0868 - accuracy: 0.9639 - val_loss: 0.0844 - val_accuracy: 0.9618\n",
      "Epoch 16/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0861 - accuracy: 0.9642 - val_loss: 0.0766 - val_accuracy: 0.9686\n",
      "Epoch 17/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0841 - accuracy: 0.9652 - val_loss: 0.0848 - val_accuracy: 0.9664\n",
      "Epoch 18/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0828 - accuracy: 0.9657 - val_loss: 0.0869 - val_accuracy: 0.9648\n",
      "Epoch 19/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0822 - accuracy: 0.9660 - val_loss: 0.0883 - val_accuracy: 0.9642\n",
      "Epoch 20/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0822 - accuracy: 0.9659 - val_loss: 0.0858 - val_accuracy: 0.9633\n",
      "Epoch 21/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0810 - accuracy: 0.9665 - val_loss: 0.0836 - val_accuracy: 0.9635\n",
      "Epoch 22/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0798 - accuracy: 0.9669 - val_loss: 0.0709 - val_accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0784 - accuracy: 0.9680 - val_loss: 0.0702 - val_accuracy: 0.9715\n",
      "Epoch 24/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0780 - accuracy: 0.9681 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
      "Epoch 25/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0764 - accuracy: 0.9685 - val_loss: 0.0820 - val_accuracy: 0.9670\n",
      "Epoch 26/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0761 - accuracy: 0.9685 - val_loss: 0.0830 - val_accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0757 - accuracy: 0.9689 - val_loss: 0.0930 - val_accuracy: 0.9648\n",
      "Epoch 28/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0745 - accuracy: 0.9695 - val_loss: 0.0730 - val_accuracy: 0.9727\n",
      "Epoch 29/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0738 - accuracy: 0.9695 - val_loss: 0.0700 - val_accuracy: 0.9705\n",
      "Epoch 30/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0746 - accuracy: 0.9694 - val_loss: 0.0796 - val_accuracy: 0.9683\n",
      "Epoch 31/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0731 - accuracy: 0.9701 - val_loss: 0.0641 - val_accuracy: 0.9743\n",
      "Epoch 32/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0731 - accuracy: 0.9701 - val_loss: 0.0760 - val_accuracy: 0.9709\n",
      "Epoch 33/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0720 - accuracy: 0.9706 - val_loss: 0.0642 - val_accuracy: 0.9738\n",
      "Epoch 34/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0718 - accuracy: 0.9705 - val_loss: 0.0653 - val_accuracy: 0.9711\n",
      "Epoch 35/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0722 - accuracy: 0.9707 - val_loss: 0.0660 - val_accuracy: 0.9717\n",
      "Epoch 36/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0715 - accuracy: 0.9709 - val_loss: 0.0666 - val_accuracy: 0.9731\n",
      "Epoch 37/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0715 - accuracy: 0.9708 - val_loss: 0.0635 - val_accuracy: 0.9740\n",
      "Epoch 38/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0699 - accuracy: 0.9714 - val_loss: 0.0615 - val_accuracy: 0.9729\n",
      "Epoch 39/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0699 - accuracy: 0.9714 - val_loss: 0.0707 - val_accuracy: 0.9719\n",
      "Epoch 40/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0700 - accuracy: 0.9714 - val_loss: 0.0648 - val_accuracy: 0.9754\n",
      "Epoch 41/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0704 - accuracy: 0.9715 - val_loss: 0.0621 - val_accuracy: 0.9741\n",
      "Epoch 42/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0691 - accuracy: 0.9718 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
      "Epoch 43/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0690 - accuracy: 0.9717 - val_loss: 0.0949 - val_accuracy: 0.9641\n",
      "Epoch 44/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0683 - accuracy: 0.9722 - val_loss: 0.0630 - val_accuracy: 0.9727\n",
      "Epoch 45/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0688 - accuracy: 0.9720 - val_loss: 0.0712 - val_accuracy: 0.9686\n",
      "Epoch 46/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0690 - accuracy: 0.9720 - val_loss: 0.0824 - val_accuracy: 0.9675\n",
      "Epoch 47/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0678 - accuracy: 0.9726 - val_loss: 0.0575 - val_accuracy: 0.9761\n",
      "Epoch 48/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0680 - accuracy: 0.9725 - val_loss: 0.0632 - val_accuracy: 0.9724\n",
      "Epoch 49/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0674 - accuracy: 0.9726 - val_loss: 0.0591 - val_accuracy: 0.9768\n",
      "Epoch 50/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0667 - accuracy: 0.9728 - val_loss: 0.0884 - val_accuracy: 0.9650\n",
      "Epoch 51/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0670 - accuracy: 0.9729 - val_loss: 0.0640 - val_accuracy: 0.9748\n",
      "Epoch 52/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0665 - accuracy: 0.9733 - val_loss: 0.0630 - val_accuracy: 0.9755\n",
      "Epoch 53/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0658 - accuracy: 0.9733 - val_loss: 0.0557 - val_accuracy: 0.9779\n",
      "Epoch 54/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0670 - accuracy: 0.9731 - val_loss: 0.0596 - val_accuracy: 0.9749\n",
      "Epoch 55/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0669 - accuracy: 0.9733 - val_loss: 0.0745 - val_accuracy: 0.9725\n",
      "Epoch 56/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0661 - accuracy: 0.9735 - val_loss: 0.0689 - val_accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0654 - accuracy: 0.9739 - val_loss: 0.0610 - val_accuracy: 0.9772\n",
      "Epoch 58/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0655 - accuracy: 0.9738 - val_loss: 0.0599 - val_accuracy: 0.9753\n",
      "Epoch 59/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0680 - accuracy: 0.9730 - val_loss: 0.0638 - val_accuracy: 0.9760\n",
      "Epoch 60/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0685 - accuracy: 0.9729 - val_loss: 0.0651 - val_accuracy: 0.9743\n",
      "Epoch 61/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0639 - accuracy: 0.9745 - val_loss: 0.0619 - val_accuracy: 0.9754\n",
      "Epoch 62/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0650 - accuracy: 0.9743 - val_loss: 0.0625 - val_accuracy: 0.9724\n",
      "Epoch 63/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0634 - accuracy: 0.9746 - val_loss: 0.0583 - val_accuracy: 0.9786\n",
      "Epoch 64/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0626 - accuracy: 0.9746 - val_loss: 0.0597 - val_accuracy: 0.9756\n",
      "Epoch 65/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0637 - accuracy: 0.9747 - val_loss: 0.0550 - val_accuracy: 0.9783\n",
      "Epoch 66/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0614 - accuracy: 0.9754 - val_loss: 0.0704 - val_accuracy: 0.9704\n",
      "Epoch 67/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0613 - accuracy: 0.9757 - val_loss: 0.0666 - val_accuracy: 0.9744\n",
      "Epoch 68/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0606 - accuracy: 0.9758 - val_loss: 0.0553 - val_accuracy: 0.9762\n",
      "Epoch 69/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0606 - accuracy: 0.9764 - val_loss: 0.0531 - val_accuracy: 0.9805\n",
      "Epoch 70/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0611 - accuracy: 0.9765 - val_loss: 0.0581 - val_accuracy: 0.9774\n",
      "Epoch 71/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 0.0652 - val_accuracy: 0.9755\n",
      "Epoch 72/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0606 - accuracy: 0.9767 - val_loss: 0.0565 - val_accuracy: 0.9765\n",
      "Epoch 73/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0596 - accuracy: 0.9770 - val_loss: 0.0568 - val_accuracy: 0.9766\n",
      "Epoch 74/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0640 - accuracy: 0.9753 - val_loss: 0.0671 - val_accuracy: 0.9749\n",
      "Epoch 75/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0601 - accuracy: 0.9764 - val_loss: 0.0560 - val_accuracy: 0.9789\n",
      "Epoch 76/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0615 - accuracy: 0.9763 - val_loss: 0.0794 - val_accuracy: 0.9700\n",
      "Epoch 77/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0666 - accuracy: 0.9749 - val_loss: 0.0611 - val_accuracy: 0.9734\n",
      "Epoch 78/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0584 - accuracy: 0.9776 - val_loss: 0.0612 - val_accuracy: 0.9774\n",
      "Epoch 79/100\n",
      "8556/8556 [==============================] - 16s 2ms/step - loss: 0.0597 - accuracy: 0.9772 - val_loss: 0.0647 - val_accuracy: 0.9755\n",
      "Epoch 80/100\n",
      "8556/8556 [==============================] - 19s 2ms/step - loss: 0.0582 - accuracy: 0.9775 - val_loss: 0.0619 - val_accuracy: 0.9759\n",
      "Epoch 81/100\n",
      "8556/8556 [==============================] - 19s 2ms/step - loss: 0.0577 - accuracy: 0.9778 - val_loss: 0.0510 - val_accuracy: 0.9797\n",
      "Epoch 82/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0579 - accuracy: 0.9779 - val_loss: 0.0567 - val_accuracy: 0.9770\n",
      "Epoch 83/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.0544 - val_accuracy: 0.9794\n",
      "Epoch 84/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0591 - accuracy: 0.9775 - val_loss: 0.0502 - val_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0580 - accuracy: 0.9778 - val_loss: 0.0532 - val_accuracy: 0.9811\n",
      "Epoch 86/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.0628 - val_accuracy: 0.9739\n",
      "Epoch 87/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0560 - accuracy: 0.9783 - val_loss: 0.0507 - val_accuracy: 0.9811\n",
      "Epoch 88/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0567 - accuracy: 0.9780 - val_loss: 0.0569 - val_accuracy: 0.9765\n",
      "Epoch 89/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0574 - accuracy: 0.9781 - val_loss: 0.0541 - val_accuracy: 0.9787\n",
      "Epoch 90/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.0544 - val_accuracy: 0.9790\n",
      "Epoch 91/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0557 - accuracy: 0.9785 - val_loss: 0.0500 - val_accuracy: 0.9817\n",
      "Epoch 92/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0548 - accuracy: 0.9787 - val_loss: 0.0703 - val_accuracy: 0.9689\n",
      "Epoch 93/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0542 - accuracy: 0.9787 - val_loss: 0.0600 - val_accuracy: 0.9742\n",
      "Epoch 94/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0537 - accuracy: 0.9788 - val_loss: 0.0534 - val_accuracy: 0.9777\n",
      "Epoch 95/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0540 - accuracy: 0.9789 - val_loss: 0.0476 - val_accuracy: 0.9818\n",
      "Epoch 96/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0528 - accuracy: 0.9791 - val_loss: 0.0541 - val_accuracy: 0.9771\n",
      "Epoch 97/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0525 - accuracy: 0.9789 - val_loss: 0.0446 - val_accuracy: 0.9825\n",
      "Epoch 98/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0528 - accuracy: 0.9789 - val_loss: 0.0583 - val_accuracy: 0.9762\n",
      "Epoch 99/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0519 - accuracy: 0.9790 - val_loss: 0.0509 - val_accuracy: 0.9812\n",
      "Epoch 100/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0548 - accuracy: 0.9792 - val_loss: 0.0499 - val_accuracy: 0.9802\n",
      "Acurácia do fold: 98.02%\n",
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.3118 - accuracy: 0.8788 - val_loss: 0.1841 - val_accuracy: 0.9348\n",
      "Epoch 2/100\n",
      "  87/8556 [..............................] - ETA: 14s - loss: 0.1811 - accuracy: 0.9289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.1669 - accuracy: 0.9370 - val_loss: 0.1639 - val_accuracy: 0.9353\n",
      "Epoch 3/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.1377 - accuracy: 0.9461 - val_loss: 0.1260 - val_accuracy: 0.9440\n",
      "Epoch 4/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.1191 - accuracy: 0.9497 - val_loss: 0.1071 - val_accuracy: 0.9543\n",
      "Epoch 5/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.1097 - accuracy: 0.9531 - val_loss: 0.1059 - val_accuracy: 0.9591\n",
      "Epoch 6/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.1055 - accuracy: 0.9548 - val_loss: 0.1136 - val_accuracy: 0.9486\n",
      "Epoch 7/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.1014 - accuracy: 0.9570 - val_loss: 0.0980 - val_accuracy: 0.9609\n",
      "Epoch 8/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0983 - accuracy: 0.9585 - val_loss: 0.0982 - val_accuracy: 0.9567\n",
      "Epoch 9/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0965 - accuracy: 0.9590 - val_loss: 0.1145 - val_accuracy: 0.9512\n",
      "Epoch 10/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0948 - accuracy: 0.9596 - val_loss: 0.0906 - val_accuracy: 0.9637\n",
      "Epoch 11/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0940 - accuracy: 0.9599 - val_loss: 0.0981 - val_accuracy: 0.9552\n",
      "Epoch 12/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0924 - accuracy: 0.9610 - val_loss: 0.0923 - val_accuracy: 0.9602\n",
      "Epoch 13/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0910 - accuracy: 0.9612 - val_loss: 0.0864 - val_accuracy: 0.9637\n",
      "Epoch 14/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.0899 - accuracy: 0.9614 - val_loss: 0.0865 - val_accuracy: 0.9639\n",
      "Epoch 15/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0890 - accuracy: 0.9622 - val_loss: 0.0898 - val_accuracy: 0.9627\n",
      "Epoch 16/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0877 - accuracy: 0.9628 - val_loss: 0.0792 - val_accuracy: 0.9666\n",
      "Epoch 17/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0862 - accuracy: 0.9631 - val_loss: 0.0807 - val_accuracy: 0.9664\n",
      "Epoch 18/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0853 - accuracy: 0.9640 - val_loss: 0.0897 - val_accuracy: 0.9613\n",
      "Epoch 19/100\n",
      "8556/8556 [==============================] - 17s 2ms/step - loss: 0.0848 - accuracy: 0.9642 - val_loss: 0.0782 - val_accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0839 - accuracy: 0.9645 - val_loss: 0.0753 - val_accuracy: 0.9677\n",
      "Epoch 21/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0826 - accuracy: 0.9651 - val_loss: 0.0821 - val_accuracy: 0.9655\n",
      "Epoch 22/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0817 - accuracy: 0.9654 - val_loss: 0.0794 - val_accuracy: 0.9681\n",
      "Epoch 23/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0809 - accuracy: 0.9655 - val_loss: 0.0855 - val_accuracy: 0.9635\n",
      "Epoch 24/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0797 - accuracy: 0.9663 - val_loss: 0.0750 - val_accuracy: 0.9674\n",
      "Epoch 25/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0796 - accuracy: 0.9661 - val_loss: 0.0776 - val_accuracy: 0.9653\n",
      "Epoch 26/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0785 - accuracy: 0.9664 - val_loss: 0.0840 - val_accuracy: 0.9648\n",
      "Epoch 27/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0776 - accuracy: 0.9672 - val_loss: 0.1003 - val_accuracy: 0.9531\n",
      "Epoch 28/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0766 - accuracy: 0.9673 - val_loss: 0.0759 - val_accuracy: 0.9678\n",
      "Epoch 29/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0762 - accuracy: 0.9674 - val_loss: 0.0699 - val_accuracy: 0.9702\n",
      "Epoch 30/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0757 - accuracy: 0.9677 - val_loss: 0.0743 - val_accuracy: 0.9692\n",
      "Epoch 31/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0750 - accuracy: 0.9682 - val_loss: 0.0737 - val_accuracy: 0.9670\n",
      "Epoch 32/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0747 - accuracy: 0.9683 - val_loss: 0.0719 - val_accuracy: 0.9671\n",
      "Epoch 33/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0741 - accuracy: 0.9684 - val_loss: 0.0719 - val_accuracy: 0.9683\n",
      "Epoch 34/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0730 - accuracy: 0.9688 - val_loss: 0.0694 - val_accuracy: 0.9707\n",
      "Epoch 35/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0731 - accuracy: 0.9691 - val_loss: 0.0664 - val_accuracy: 0.9707\n",
      "Epoch 36/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0725 - accuracy: 0.9694 - val_loss: 0.0649 - val_accuracy: 0.9716\n",
      "Epoch 37/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0725 - accuracy: 0.9692 - val_loss: 0.0739 - val_accuracy: 0.9689\n",
      "Epoch 38/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0720 - accuracy: 0.9695 - val_loss: 0.0658 - val_accuracy: 0.9725\n",
      "Epoch 39/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.0714 - accuracy: 0.9697 - val_loss: 0.0758 - val_accuracy: 0.9642\n",
      "Epoch 40/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0717 - accuracy: 0.9696 - val_loss: 0.0752 - val_accuracy: 0.9675\n",
      "Epoch 41/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0713 - accuracy: 0.9698 - val_loss: 0.0742 - val_accuracy: 0.9669\n",
      "Epoch 42/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0714 - accuracy: 0.9697 - val_loss: 0.0773 - val_accuracy: 0.9655\n",
      "Epoch 43/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0709 - accuracy: 0.9699 - val_loss: 0.0699 - val_accuracy: 0.9699\n",
      "Epoch 44/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0700 - accuracy: 0.9702 - val_loss: 0.0751 - val_accuracy: 0.9682\n",
      "Epoch 45/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0698 - accuracy: 0.9705 - val_loss: 0.0631 - val_accuracy: 0.9729\n",
      "Epoch 46/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0699 - accuracy: 0.9704 - val_loss: 0.0711 - val_accuracy: 0.9707\n",
      "Epoch 47/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0696 - accuracy: 0.9706 - val_loss: 0.0680 - val_accuracy: 0.9721\n",
      "Epoch 48/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0693 - accuracy: 0.9707 - val_loss: 0.0647 - val_accuracy: 0.9720\n",
      "Epoch 49/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0688 - accuracy: 0.9709 - val_loss: 0.0636 - val_accuracy: 0.9737\n",
      "Epoch 50/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0682 - accuracy: 0.9713 - val_loss: 0.0723 - val_accuracy: 0.9699\n",
      "Epoch 51/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0681 - accuracy: 0.9712 - val_loss: 0.0712 - val_accuracy: 0.9707\n",
      "Epoch 52/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0686 - accuracy: 0.9710 - val_loss: 0.0654 - val_accuracy: 0.9719\n",
      "Epoch 53/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0680 - accuracy: 0.9711 - val_loss: 0.0630 - val_accuracy: 0.9727\n",
      "Epoch 54/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0674 - accuracy: 0.9714 - val_loss: 0.0673 - val_accuracy: 0.9713\n",
      "Epoch 55/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0670 - accuracy: 0.9716 - val_loss: 0.0629 - val_accuracy: 0.9729\n",
      "Epoch 56/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0671 - accuracy: 0.9715 - val_loss: 0.0657 - val_accuracy: 0.9716\n",
      "Epoch 57/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0670 - accuracy: 0.9717 - val_loss: 0.0646 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0667 - accuracy: 0.9717 - val_loss: 0.0622 - val_accuracy: 0.9741\n",
      "Epoch 59/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0660 - accuracy: 0.9719 - val_loss: 0.0800 - val_accuracy: 0.9645\n",
      "Epoch 60/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0659 - accuracy: 0.9719 - val_loss: 0.0652 - val_accuracy: 0.9730\n",
      "Epoch 61/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0655 - accuracy: 0.9719 - val_loss: 0.0688 - val_accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0659 - accuracy: 0.9722 - val_loss: 0.0629 - val_accuracy: 0.9735\n",
      "Epoch 63/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0656 - accuracy: 0.9721 - val_loss: 0.0768 - val_accuracy: 0.9681\n",
      "Epoch 64/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0652 - accuracy: 0.9723 - val_loss: 0.0608 - val_accuracy: 0.9736\n",
      "Epoch 65/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0652 - accuracy: 0.9721 - val_loss: 0.0770 - val_accuracy: 0.9692\n",
      "Epoch 66/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0646 - accuracy: 0.9725 - val_loss: 0.0586 - val_accuracy: 0.9750\n",
      "Epoch 67/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0647 - accuracy: 0.9725 - val_loss: 0.0583 - val_accuracy: 0.9748\n",
      "Epoch 68/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0643 - accuracy: 0.9727 - val_loss: 0.0663 - val_accuracy: 0.9701\n",
      "Epoch 69/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0646 - accuracy: 0.9725 - val_loss: 0.0608 - val_accuracy: 0.9739\n",
      "Epoch 70/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0642 - accuracy: 0.9726 - val_loss: 0.0615 - val_accuracy: 0.9737\n",
      "Epoch 71/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0641 - accuracy: 0.9729 - val_loss: 0.0702 - val_accuracy: 0.9687\n",
      "Epoch 72/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0637 - accuracy: 0.9730 - val_loss: 0.0652 - val_accuracy: 0.9722\n",
      "Epoch 73/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0639 - accuracy: 0.9730 - val_loss: 0.0673 - val_accuracy: 0.9723\n",
      "Epoch 74/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0636 - accuracy: 0.9730 - val_loss: 0.0632 - val_accuracy: 0.9738\n",
      "Epoch 75/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0631 - accuracy: 0.9732 - val_loss: 0.0663 - val_accuracy: 0.9743\n",
      "Epoch 76/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0636 - accuracy: 0.9731 - val_loss: 0.0580 - val_accuracy: 0.9756\n",
      "Epoch 77/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0633 - accuracy: 0.9731 - val_loss: 0.0634 - val_accuracy: 0.9743\n",
      "Epoch 78/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0630 - accuracy: 0.9732 - val_loss: 0.0606 - val_accuracy: 0.9739\n",
      "Epoch 79/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0628 - accuracy: 0.9732 - val_loss: 0.0666 - val_accuracy: 0.9713\n",
      "Epoch 80/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0627 - accuracy: 0.9729 - val_loss: 0.0716 - val_accuracy: 0.9693\n",
      "Epoch 81/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0630 - accuracy: 0.9731 - val_loss: 0.0601 - val_accuracy: 0.9732\n",
      "Epoch 82/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0622 - accuracy: 0.9734 - val_loss: 0.0694 - val_accuracy: 0.9680\n",
      "Epoch 83/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.0627 - accuracy: 0.9733 - val_loss: 0.0820 - val_accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0618 - accuracy: 0.9737 - val_loss: 0.0611 - val_accuracy: 0.9739\n",
      "Epoch 85/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0624 - accuracy: 0.9732 - val_loss: 0.0581 - val_accuracy: 0.9746\n",
      "Epoch 86/100\n",
      "8556/8556 [==============================] - 18s 2ms/step - loss: 0.0622 - accuracy: 0.9735 - val_loss: 0.0616 - val_accuracy: 0.9723\n",
      "Epoch 87/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.0621 - accuracy: 0.9734 - val_loss: 0.0587 - val_accuracy: 0.9755\n",
      "Epoch 88/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0620 - accuracy: 0.9737 - val_loss: 0.0611 - val_accuracy: 0.9732\n",
      "Epoch 89/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0619 - accuracy: 0.9736 - val_loss: 0.0573 - val_accuracy: 0.9754\n",
      "Epoch 90/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0615 - accuracy: 0.9735 - val_loss: 0.0633 - val_accuracy: 0.9733\n",
      "Epoch 91/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0613 - accuracy: 0.9737 - val_loss: 0.0641 - val_accuracy: 0.9725\n",
      "Epoch 92/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0614 - accuracy: 0.9738 - val_loss: 0.0631 - val_accuracy: 0.9725\n",
      "Epoch 93/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0609 - accuracy: 0.9738 - val_loss: 0.0611 - val_accuracy: 0.9751\n",
      "Epoch 94/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0613 - accuracy: 0.9737 - val_loss: 0.0589 - val_accuracy: 0.9737\n",
      "Epoch 95/100\n",
      "8556/8556 [==============================] - 17s 2ms/step - loss: 0.0607 - accuracy: 0.9740 - val_loss: 0.0603 - val_accuracy: 0.9739\n",
      "Epoch 96/100\n",
      "8556/8556 [==============================] - 14s 2ms/step - loss: 0.0610 - accuracy: 0.9739 - val_loss: 0.0665 - val_accuracy: 0.9687\n",
      "Epoch 97/100\n",
      "8556/8556 [==============================] - 15s 2ms/step - loss: 0.0604 - accuracy: 0.9738 - val_loss: 0.0582 - val_accuracy: 0.9749\n",
      "Epoch 98/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0610 - accuracy: 0.9739 - val_loss: 0.0624 - val_accuracy: 0.9723\n",
      "Epoch 99/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0604 - accuracy: 0.9741 - val_loss: 0.0574 - val_accuracy: 0.9752\n",
      "Epoch 100/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0601 - accuracy: 0.9743 - val_loss: 0.0587 - val_accuracy: 0.9758\n",
      "Acurácia do fold: 97.58%\n",
      "Epoch 1/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.3422 - accuracy: 0.8590 - val_loss: 0.2228 - val_accuracy: 0.8964\n",
      "Epoch 2/100\n",
      " 109/8556 [..............................] - ETA: 11s - loss: 0.2326 - accuracy: 0.8928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.2106 - accuracy: 0.9022 - val_loss: 0.1894 - val_accuracy: 0.9055\n",
      "Epoch 3/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1793 - accuracy: 0.9214 - val_loss: 0.1590 - val_accuracy: 0.9459\n",
      "Epoch 4/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1503 - accuracy: 0.9401 - val_loss: 0.1288 - val_accuracy: 0.9479\n",
      "Epoch 5/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.1310 - accuracy: 0.9468 - val_loss: 0.1267 - val_accuracy: 0.9521\n",
      "Epoch 6/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1199 - accuracy: 0.9510 - val_loss: 0.1255 - val_accuracy: 0.9431\n",
      "Epoch 7/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.1122 - accuracy: 0.9537 - val_loss: 0.1095 - val_accuracy: 0.9569\n",
      "Epoch 8/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1072 - accuracy: 0.9557 - val_loss: 0.0997 - val_accuracy: 0.9607\n",
      "Epoch 9/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.1025 - accuracy: 0.9574 - val_loss: 0.1033 - val_accuracy: 0.9513\n",
      "Epoch 10/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0999 - accuracy: 0.9582 - val_loss: 0.0988 - val_accuracy: 0.9584\n",
      "Epoch 11/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0970 - accuracy: 0.9595 - val_loss: 0.0899 - val_accuracy: 0.9597\n",
      "Epoch 12/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0944 - accuracy: 0.9603 - val_loss: 0.0926 - val_accuracy: 0.9592\n",
      "Epoch 13/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0930 - accuracy: 0.9605 - val_loss: 0.0937 - val_accuracy: 0.9652\n",
      "Epoch 14/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0907 - accuracy: 0.9616 - val_loss: 0.0918 - val_accuracy: 0.9590\n",
      "Epoch 15/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0889 - accuracy: 0.9624 - val_loss: 0.0819 - val_accuracy: 0.9666\n",
      "Epoch 16/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0863 - accuracy: 0.9633 - val_loss: 0.0863 - val_accuracy: 0.9645\n",
      "Epoch 17/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0845 - accuracy: 0.9641 - val_loss: 0.0809 - val_accuracy: 0.9646\n",
      "Epoch 18/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0823 - accuracy: 0.9647 - val_loss: 0.0753 - val_accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0809 - accuracy: 0.9650 - val_loss: 0.0806 - val_accuracy: 0.9685\n",
      "Epoch 20/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0797 - accuracy: 0.9657 - val_loss: 0.0766 - val_accuracy: 0.9685\n",
      "Epoch 21/100\n",
      "8556/8556 [==============================] - 13s 1ms/step - loss: 0.0782 - accuracy: 0.9663 - val_loss: 0.0795 - val_accuracy: 0.9649\n",
      "Epoch 22/100\n",
      "8556/8556 [==============================] - 13s 2ms/step - loss: 0.0773 - accuracy: 0.9668 - val_loss: 0.0781 - val_accuracy: 0.9644\n",
      "Epoch 23/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0764 - accuracy: 0.9672 - val_loss: 0.0948 - val_accuracy: 0.9637\n",
      "Epoch 24/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0760 - accuracy: 0.9675 - val_loss: 0.0716 - val_accuracy: 0.9705\n",
      "Epoch 25/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0748 - accuracy: 0.9678 - val_loss: 0.0699 - val_accuracy: 0.9679\n",
      "Epoch 26/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0739 - accuracy: 0.9682 - val_loss: 0.0731 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0731 - accuracy: 0.9686 - val_loss: 0.0763 - val_accuracy: 0.9643\n",
      "Epoch 28/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0722 - accuracy: 0.9690 - val_loss: 0.0684 - val_accuracy: 0.9719\n",
      "Epoch 29/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0720 - accuracy: 0.9692 - val_loss: 0.0634 - val_accuracy: 0.9731\n",
      "Epoch 30/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0711 - accuracy: 0.9695 - val_loss: 0.0713 - val_accuracy: 0.9695\n",
      "Epoch 31/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0708 - accuracy: 0.9695 - val_loss: 0.0628 - val_accuracy: 0.9744\n",
      "Epoch 32/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0701 - accuracy: 0.9700 - val_loss: 0.0660 - val_accuracy: 0.9731\n",
      "Epoch 33/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0705 - accuracy: 0.9699 - val_loss: 0.0780 - val_accuracy: 0.9704\n",
      "Epoch 34/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0700 - accuracy: 0.9701 - val_loss: 0.0698 - val_accuracy: 0.9721\n",
      "Epoch 35/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0696 - accuracy: 0.9703 - val_loss: 0.0754 - val_accuracy: 0.9677\n",
      "Epoch 36/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0691 - accuracy: 0.9704 - val_loss: 0.0750 - val_accuracy: 0.9679\n",
      "Epoch 37/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0685 - accuracy: 0.9706 - val_loss: 0.0595 - val_accuracy: 0.9759\n",
      "Epoch 38/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0682 - accuracy: 0.9709 - val_loss: 0.0834 - val_accuracy: 0.9617\n",
      "Epoch 39/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0676 - accuracy: 0.9712 - val_loss: 0.0707 - val_accuracy: 0.9668\n",
      "Epoch 40/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0673 - accuracy: 0.9715 - val_loss: 0.0643 - val_accuracy: 0.9736\n",
      "Epoch 41/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0674 - accuracy: 0.9714 - val_loss: 0.0733 - val_accuracy: 0.9711\n",
      "Epoch 42/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0668 - accuracy: 0.9718 - val_loss: 0.0578 - val_accuracy: 0.9762\n",
      "Epoch 43/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0666 - accuracy: 0.9718 - val_loss: 0.0738 - val_accuracy: 0.9717\n",
      "Epoch 44/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0656 - accuracy: 0.9722 - val_loss: 0.0680 - val_accuracy: 0.9692\n",
      "Epoch 45/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0657 - accuracy: 0.9722 - val_loss: 0.0721 - val_accuracy: 0.9698\n",
      "Epoch 46/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0651 - accuracy: 0.9725 - val_loss: 0.0652 - val_accuracy: 0.9723\n",
      "Epoch 47/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0643 - accuracy: 0.9728 - val_loss: 0.0760 - val_accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0647 - accuracy: 0.9728 - val_loss: 0.0559 - val_accuracy: 0.9777\n",
      "Epoch 49/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0636 - accuracy: 0.9730 - val_loss: 0.0588 - val_accuracy: 0.9743\n",
      "Epoch 50/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0630 - accuracy: 0.9735 - val_loss: 0.0587 - val_accuracy: 0.9740\n",
      "Epoch 51/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0629 - accuracy: 0.9732 - val_loss: 0.0527 - val_accuracy: 0.9771\n",
      "Epoch 52/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0627 - accuracy: 0.9736 - val_loss: 0.0600 - val_accuracy: 0.9759\n",
      "Epoch 53/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0621 - accuracy: 0.9736 - val_loss: 0.0562 - val_accuracy: 0.9758\n",
      "Epoch 54/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0609 - accuracy: 0.9744 - val_loss: 0.0717 - val_accuracy: 0.9718\n",
      "Epoch 55/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0612 - accuracy: 0.9745 - val_loss: 0.0568 - val_accuracy: 0.9770\n",
      "Epoch 56/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0599 - accuracy: 0.9750 - val_loss: 0.0601 - val_accuracy: 0.9745\n",
      "Epoch 57/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0592 - accuracy: 0.9756 - val_loss: 0.0514 - val_accuracy: 0.9796\n",
      "Epoch 58/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0582 - accuracy: 0.9757 - val_loss: 0.0558 - val_accuracy: 0.9784\n",
      "Epoch 59/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0581 - accuracy: 0.9757 - val_loss: 0.0782 - val_accuracy: 0.9691\n",
      "Epoch 60/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0573 - accuracy: 0.9765 - val_loss: 0.0561 - val_accuracy: 0.9757\n",
      "Epoch 61/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0566 - accuracy: 0.9764 - val_loss: 0.0600 - val_accuracy: 0.9756\n",
      "Epoch 62/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0563 - accuracy: 0.9769 - val_loss: 0.0504 - val_accuracy: 0.9801\n",
      "Epoch 63/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0548 - accuracy: 0.9772 - val_loss: 0.0581 - val_accuracy: 0.9756\n",
      "Epoch 64/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0538 - accuracy: 0.9777 - val_loss: 0.0466 - val_accuracy: 0.9808\n",
      "Epoch 65/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0535 - accuracy: 0.9779 - val_loss: 0.0509 - val_accuracy: 0.9804\n",
      "Epoch 66/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0526 - accuracy: 0.9784 - val_loss: 0.0442 - val_accuracy: 0.9824\n",
      "Epoch 67/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0522 - accuracy: 0.9782 - val_loss: 0.0592 - val_accuracy: 0.9737\n",
      "Epoch 68/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0510 - accuracy: 0.9787 - val_loss: 0.0458 - val_accuracy: 0.9821\n",
      "Epoch 69/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0509 - accuracy: 0.9789 - val_loss: 0.0617 - val_accuracy: 0.9752\n",
      "Epoch 70/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0511 - accuracy: 0.9791 - val_loss: 0.0582 - val_accuracy: 0.9773\n",
      "Epoch 71/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0510 - accuracy: 0.9789 - val_loss: 0.0446 - val_accuracy: 0.9808\n",
      "Epoch 72/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0501 - accuracy: 0.9791 - val_loss: 0.0437 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "8556/8556 [==============================] - 12s 1ms/step - loss: 0.0498 - accuracy: 0.9794 - val_loss: 0.0449 - val_accuracy: 0.9817\n",
      "Epoch 74/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0493 - accuracy: 0.9794 - val_loss: 0.0528 - val_accuracy: 0.9774\n",
      "Epoch 75/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0496 - accuracy: 0.9793 - val_loss: 0.0450 - val_accuracy: 0.9805\n",
      "Epoch 76/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0488 - accuracy: 0.9797 - val_loss: 0.0561 - val_accuracy: 0.9778\n",
      "Epoch 77/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0484 - accuracy: 0.9798 - val_loss: 0.0516 - val_accuracy: 0.9803\n",
      "Epoch 78/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0485 - accuracy: 0.9797 - val_loss: 0.0435 - val_accuracy: 0.9809\n",
      "Epoch 79/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0481 - accuracy: 0.9797 - val_loss: 0.0420 - val_accuracy: 0.9816\n",
      "Epoch 80/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0479 - accuracy: 0.9801 - val_loss: 0.0454 - val_accuracy: 0.9797\n",
      "Epoch 81/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0479 - accuracy: 0.9800 - val_loss: 0.0506 - val_accuracy: 0.9780\n",
      "Epoch 82/100\n",
      "8556/8556 [==============================] - 11s 1ms/step - loss: 0.0475 - accuracy: 0.9800 - val_loss: 0.0537 - val_accuracy: 0.9784\n",
      "Epoch 83/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0474 - accuracy: 0.9801 - val_loss: 0.0476 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0475 - accuracy: 0.9800 - val_loss: 0.0439 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0472 - accuracy: 0.9802 - val_loss: 0.0433 - val_accuracy: 0.9812\n",
      "Epoch 86/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0462 - accuracy: 0.9804 - val_loss: 0.0382 - val_accuracy: 0.9832\n",
      "Epoch 87/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0469 - accuracy: 0.9804 - val_loss: 0.0402 - val_accuracy: 0.9824\n",
      "Epoch 88/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0463 - accuracy: 0.9803 - val_loss: 0.0467 - val_accuracy: 0.9793\n",
      "Epoch 89/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0459 - accuracy: 0.9804 - val_loss: 0.0533 - val_accuracy: 0.9779\n",
      "Epoch 90/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0465 - accuracy: 0.9804 - val_loss: 0.0400 - val_accuracy: 0.9819\n",
      "Epoch 91/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0460 - accuracy: 0.9807 - val_loss: 0.0537 - val_accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0456 - accuracy: 0.9809 - val_loss: 0.0381 - val_accuracy: 0.9830\n",
      "Epoch 93/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0455 - accuracy: 0.9810 - val_loss: 0.0402 - val_accuracy: 0.9826\n",
      "Epoch 94/100\n",
      "8556/8556 [==============================] - 9s 1ms/step - loss: 0.0450 - accuracy: 0.9811 - val_loss: 0.0422 - val_accuracy: 0.9826\n",
      "Epoch 95/100\n",
      "8556/8556 [==============================] - 9s 1ms/step - loss: 0.0451 - accuracy: 0.9810 - val_loss: 0.0541 - val_accuracy: 0.9784\n",
      "Epoch 96/100\n",
      "8556/8556 [==============================] - 9s 1ms/step - loss: 0.0451 - accuracy: 0.9811 - val_loss: 0.0369 - val_accuracy: 0.9839\n",
      "Epoch 97/100\n",
      "8556/8556 [==============================] - 9s 1ms/step - loss: 0.0446 - accuracy: 0.9813 - val_loss: 0.0511 - val_accuracy: 0.9766\n",
      "Epoch 98/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0446 - accuracy: 0.9811 - val_loss: 0.0383 - val_accuracy: 0.9851\n",
      "Epoch 99/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0441 - accuracy: 0.9815 - val_loss: 0.0416 - val_accuracy: 0.9814\n",
      "Epoch 100/100\n",
      "8556/8556 [==============================] - 10s 1ms/step - loss: 0.0484 - accuracy: 0.9812 - val_loss: 0.0504 - val_accuracy: 0.9813\n",
      "Acurácia do fold: 98.13%\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "histories = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_k_norm):\n",
    "    # Divida os dados em treino e validação\n",
    "    X_train_fold, X_val_fold = X_train_k_norm.iloc[train_index], X_train_k_norm.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_k.iloc[train_index], y_train_k.iloc[val_index]\n",
    "\n",
    "    model_2 = Sequential()\n",
    "\n",
    "    # Adicione as camadas ocultas\n",
    "    model_2.add(Dense(32, input_dim=4, activation='relu'))  # Camada de entrada com 8 neurônios e ativação ReLU\n",
    "    model_2.add(Dense(16, activation='relu'))  # Segunda camada oculta com 3 neurônios e ativação ReLU (opcional)\n",
    "    model_2.add(Dense(8, activation='relu'))\n",
    "\n",
    "    # Adicione a camada de saída\n",
    "    model_2.add(Dense(6, activation='softmax'))  # Camada de saída com 5 neurônios (um para cada classe) e ativação Softmax para classificação multiclasse\n",
    "\n",
    "    # Compile o model_2o\n",
    "    model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Defina o checkpoint para salvar os pesos\n",
    "    checkpoint = ModelCheckpoint(\"weights_only.h5\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # Treine o model_2o com conjunto de validação e o checkpoint\n",
    "    history = model_2.fit(X_train_fold, y_train_fold, epochs=100, batch_size=64, validation_data=(X_val_fold, y_val_fold), callbacks=[checkpoint])\n",
    "    histories.append(history.history)\n",
    "\n",
    "    # Avalie o modelo\n",
    "    _, accuracy = model_2.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Acurácia do fold: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia média: 98.04%\n",
      "Desvio padrão da acurácia: 0.28%\n"
     ]
    }
   ],
   "source": [
    "mean_accuracy = np.mean(accuracies)\n",
    "std_accuracy = np.std(accuracies)\n",
    "print(f'\\nAcurácia média: {mean_accuracy*100:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Salvar accuracies em um arquivo JSON\n",
    "with open('accuracies_rede_unica.json', 'w') as f:\n",
    "    json.dump(accuracies, f)\n",
    "\n",
    "# Salvar histories em um arquivo JSON\n",
    "with open('histories_rede_unica.json', 'w') as f:\n",
    "    json.dump(histories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47909/47909 [==============================] - 91s 2ms/step - loss: 0.2546 - accuracy: 0.8913 - val_loss: 0.1717 - val_accuracy: 0.9265\n",
      "Epoch 2/100\n",
      "   99/47909 [..............................] - ETA: 1:14 - loss: 0.1617 - accuracy: 0.9273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\Documents\\0_python_env\\venv3WPetrobras\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47909/47909 [==============================] - 89s 2ms/step - loss: 0.1313 - accuracy: 0.9457 - val_loss: 0.1137 - val_accuracy: 0.9572\n",
      "Epoch 3/100\n",
      "47909/47909 [==============================] - 88s 2ms/step - loss: 0.1192 - accuracy: 0.9501 - val_loss: 0.1028 - val_accuracy: 0.9584\n",
      "Epoch 4/100\n",
      "47909/47909 [==============================] - 85s 2ms/step - loss: 0.1158 - accuracy: 0.9517 - val_loss: 0.1248 - val_accuracy: 0.9490\n",
      "Epoch 5/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.1116 - accuracy: 0.9532 - val_loss: 0.1281 - val_accuracy: 0.9459\n",
      "Epoch 6/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.1083 - accuracy: 0.9545 - val_loss: 0.1037 - val_accuracy: 0.9573\n",
      "Epoch 7/100\n",
      "47909/47909 [==============================] - 79s 2ms/step - loss: 0.1052 - accuracy: 0.9559 - val_loss: 0.0959 - val_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.1026 - accuracy: 0.9567 - val_loss: 0.0872 - val_accuracy: 0.9617\n",
      "Epoch 9/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.1002 - accuracy: 0.9575 - val_loss: 0.0945 - val_accuracy: 0.9599\n",
      "Epoch 10/100\n",
      "47909/47909 [==============================] - 108s 2ms/step - loss: 0.0983 - accuracy: 0.9578 - val_loss: 0.1061 - val_accuracy: 0.9549\n",
      "Epoch 11/100\n",
      "47909/47909 [==============================] - 105s 2ms/step - loss: 0.0962 - accuracy: 0.9591 - val_loss: 0.1003 - val_accuracy: 0.9585\n",
      "Epoch 12/100\n",
      "47909/47909 [==============================] - 104s 2ms/step - loss: 0.0942 - accuracy: 0.9595 - val_loss: 0.1218 - val_accuracy: 0.9451\n",
      "Epoch 13/100\n",
      "47909/47909 [==============================] - 102s 2ms/step - loss: 0.0933 - accuracy: 0.9600 - val_loss: 0.0809 - val_accuracy: 0.9635\n",
      "Epoch 14/100\n",
      "47909/47909 [==============================] - 96s 2ms/step - loss: 0.0907 - accuracy: 0.9610 - val_loss: 0.0873 - val_accuracy: 0.9606\n",
      "Epoch 15/100\n",
      "47909/47909 [==============================] - 97s 2ms/step - loss: 0.0886 - accuracy: 0.9615 - val_loss: 0.0840 - val_accuracy: 0.9656\n",
      "Epoch 16/100\n",
      "47909/47909 [==============================] - 99s 2ms/step - loss: 0.0868 - accuracy: 0.9624 - val_loss: 0.0710 - val_accuracy: 0.9692\n",
      "Epoch 17/100\n",
      "47909/47909 [==============================] - 106s 2ms/step - loss: 0.0859 - accuracy: 0.9629 - val_loss: 0.0757 - val_accuracy: 0.9663\n",
      "Epoch 18/100\n",
      "47909/47909 [==============================] - 106s 2ms/step - loss: 0.0847 - accuracy: 0.9633 - val_loss: 0.0734 - val_accuracy: 0.9676\n",
      "Epoch 19/100\n",
      "47909/47909 [==============================] - 106s 2ms/step - loss: 0.0832 - accuracy: 0.9641 - val_loss: 0.0859 - val_accuracy: 0.9627\n",
      "Epoch 20/100\n",
      "47909/47909 [==============================] - 107s 2ms/step - loss: 0.0841 - accuracy: 0.9637 - val_loss: 0.1087 - val_accuracy: 0.9619\n",
      "Epoch 21/100\n",
      "47909/47909 [==============================] - 101s 2ms/step - loss: 0.0805 - accuracy: 0.9650 - val_loss: 0.0769 - val_accuracy: 0.9651\n",
      "Epoch 22/100\n",
      "47909/47909 [==============================] - 104s 2ms/step - loss: 0.0792 - accuracy: 0.9657 - val_loss: 0.0822 - val_accuracy: 0.9646\n",
      "Epoch 23/100\n",
      "47909/47909 [==============================] - 103s 2ms/step - loss: 0.0783 - accuracy: 0.9662 - val_loss: 0.0688 - val_accuracy: 0.9722\n",
      "Epoch 24/100\n",
      "47909/47909 [==============================] - 95s 2ms/step - loss: 0.0777 - accuracy: 0.9667 - val_loss: 0.0631 - val_accuracy: 0.9733\n",
      "Epoch 25/100\n",
      "47909/47909 [==============================] - 87s 2ms/step - loss: 0.0758 - accuracy: 0.9679 - val_loss: 0.0744 - val_accuracy: 0.9692\n",
      "Epoch 26/100\n",
      "47909/47909 [==============================] - 89s 2ms/step - loss: 0.0743 - accuracy: 0.9689 - val_loss: 0.0785 - val_accuracy: 0.9670\n",
      "Epoch 27/100\n",
      "47909/47909 [==============================] - 88s 2ms/step - loss: 0.0737 - accuracy: 0.9685 - val_loss: 0.0620 - val_accuracy: 0.9744\n",
      "Epoch 28/100\n",
      "47909/47909 [==============================] - 86s 2ms/step - loss: 0.0705 - accuracy: 0.9702 - val_loss: 0.0604 - val_accuracy: 0.9727\n",
      "Epoch 29/100\n",
      "47909/47909 [==============================] - 87s 2ms/step - loss: 0.0701 - accuracy: 0.9705 - val_loss: 0.0597 - val_accuracy: 0.9736\n",
      "Epoch 30/100\n",
      "47909/47909 [==============================] - 87s 2ms/step - loss: 0.0716 - accuracy: 0.9704 - val_loss: 0.0684 - val_accuracy: 0.9746\n",
      "Epoch 31/100\n",
      "47909/47909 [==============================] - 90s 2ms/step - loss: 0.0738 - accuracy: 0.9698 - val_loss: 0.0718 - val_accuracy: 0.9683\n",
      "Epoch 32/100\n",
      "47909/47909 [==============================] - 89s 2ms/step - loss: 0.0733 - accuracy: 0.9693 - val_loss: 0.0583 - val_accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "47909/47909 [==============================] - 90s 2ms/step - loss: 0.0702 - accuracy: 0.9705 - val_loss: 0.1648 - val_accuracy: 0.9495\n",
      "Epoch 34/100\n",
      "47909/47909 [==============================] - 85s 2ms/step - loss: 0.0699 - accuracy: 0.9711 - val_loss: 0.0627 - val_accuracy: 0.9728\n",
      "Epoch 35/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.0692 - accuracy: 0.9712 - val_loss: 0.0732 - val_accuracy: 0.9721\n",
      "Epoch 36/100\n",
      "47909/47909 [==============================] - 86s 2ms/step - loss: 0.0690 - accuracy: 0.9713 - val_loss: 0.0680 - val_accuracy: 0.9716\n",
      "Epoch 37/100\n",
      "47909/47909 [==============================] - 88s 2ms/step - loss: 0.0776 - accuracy: 0.9686 - val_loss: 0.0564 - val_accuracy: 0.9770\n",
      "Epoch 38/100\n",
      "47909/47909 [==============================] - 72s 2ms/step - loss: 0.0694 - accuracy: 0.9717 - val_loss: 0.0546 - val_accuracy: 0.9784\n",
      "Epoch 39/100\n",
      "47909/47909 [==============================] - 68s 1ms/step - loss: 0.0699 - accuracy: 0.9716 - val_loss: 0.0740 - val_accuracy: 0.9723\n",
      "Epoch 40/100\n",
      "47909/47909 [==============================] - 66s 1ms/step - loss: 0.0754 - accuracy: 0.9695 - val_loss: 0.0743 - val_accuracy: 0.9702\n",
      "Epoch 41/100\n",
      "47909/47909 [==============================] - 67s 1ms/step - loss: 0.0743 - accuracy: 0.9698 - val_loss: 0.0938 - val_accuracy: 0.9589\n",
      "Epoch 42/100\n",
      "47909/47909 [==============================] - 69s 1ms/step - loss: 0.0756 - accuracy: 0.9689 - val_loss: 0.0610 - val_accuracy: 0.9758\n",
      "Epoch 43/100\n",
      "47909/47909 [==============================] - 71s 1ms/step - loss: 0.0666 - accuracy: 0.9724 - val_loss: 0.0811 - val_accuracy: 0.9677\n",
      "Epoch 44/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.0660 - accuracy: 0.9729 - val_loss: 0.0818 - val_accuracy: 0.9660\n",
      "Epoch 45/100\n",
      "47909/47909 [==============================] - 97s 2ms/step - loss: 0.0736 - accuracy: 0.9706 - val_loss: 0.0636 - val_accuracy: 0.9733\n",
      "Epoch 46/100\n",
      "47909/47909 [==============================] - 84s 2ms/step - loss: 0.0699 - accuracy: 0.9721 - val_loss: 0.0583 - val_accuracy: 0.9757\n",
      "Epoch 47/100\n",
      "47909/47909 [==============================] - 77s 2ms/step - loss: 0.0639 - accuracy: 0.9734 - val_loss: 0.0680 - val_accuracy: 0.9725\n",
      "Epoch 48/100\n",
      "47909/47909 [==============================] - 73s 2ms/step - loss: 0.0628 - accuracy: 0.9742 - val_loss: 0.0579 - val_accuracy: 0.9747\n",
      "Epoch 49/100\n",
      "47909/47909 [==============================] - 71s 1ms/step - loss: 0.0635 - accuracy: 0.9740 - val_loss: 0.0769 - val_accuracy: 0.9665\n",
      "Epoch 50/100\n",
      "47909/47909 [==============================] - 87s 2ms/step - loss: 0.0670 - accuracy: 0.9725 - val_loss: 0.0639 - val_accuracy: 0.9759\n",
      "Epoch 51/100\n",
      "47909/47909 [==============================] - 76s 2ms/step - loss: 0.0745 - accuracy: 0.9699 - val_loss: 0.0891 - val_accuracy: 0.9649\n",
      "Epoch 52/100\n",
      "47909/47909 [==============================] - 76s 2ms/step - loss: 0.0758 - accuracy: 0.9705 - val_loss: 0.0603 - val_accuracy: 0.9770\n",
      "Epoch 53/100\n",
      "47909/47909 [==============================] - 79s 2ms/step - loss: 0.0714 - accuracy: 0.9719 - val_loss: 0.0867 - val_accuracy: 0.9609\n",
      "Epoch 54/100\n",
      "47909/47909 [==============================] - 70s 1ms/step - loss: 0.0696 - accuracy: 0.9722 - val_loss: 0.0675 - val_accuracy: 0.9696\n",
      "Epoch 55/100\n",
      "47909/47909 [==============================] - 76s 2ms/step - loss: 0.0734 - accuracy: 0.9708 - val_loss: 0.0637 - val_accuracy: 0.9747\n",
      "Epoch 56/100\n",
      "47909/47909 [==============================] - 72s 1ms/step - loss: 0.0707 - accuracy: 0.9721 - val_loss: 0.0935 - val_accuracy: 0.9656\n",
      "Epoch 57/100\n",
      "47909/47909 [==============================] - 75s 2ms/step - loss: 0.0661 - accuracy: 0.9733 - val_loss: 0.0623 - val_accuracy: 0.9725\n",
      "Epoch 58/100\n",
      "47909/47909 [==============================] - 75s 2ms/step - loss: 0.0638 - accuracy: 0.9738 - val_loss: 0.0572 - val_accuracy: 0.9762\n",
      "Epoch 59/100\n",
      "47909/47909 [==============================] - 73s 2ms/step - loss: 0.0652 - accuracy: 0.9735 - val_loss: 0.0627 - val_accuracy: 0.9719\n",
      "Epoch 60/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.0636 - accuracy: 0.9738 - val_loss: 0.1625 - val_accuracy: 0.9622\n",
      "Epoch 61/100\n",
      "47909/47909 [==============================] - 82s 2ms/step - loss: 0.0644 - accuracy: 0.9738 - val_loss: 0.0689 - val_accuracy: 0.9726\n",
      "Epoch 62/100\n",
      "47909/47909 [==============================] - 81s 2ms/step - loss: 0.0675 - accuracy: 0.9722 - val_loss: 0.0661 - val_accuracy: 0.9747\n",
      "Epoch 63/100\n",
      "47909/47909 [==============================] - 75s 2ms/step - loss: 0.0724 - accuracy: 0.9710 - val_loss: 0.0681 - val_accuracy: 0.9706\n",
      "Epoch 64/100\n",
      "47909/47909 [==============================] - 77s 2ms/step - loss: 0.0688 - accuracy: 0.9725 - val_loss: 0.0551 - val_accuracy: 0.9772\n",
      "Epoch 65/100\n",
      "47909/47909 [==============================] - 80s 2ms/step - loss: 0.0698 - accuracy: 0.9721 - val_loss: 0.0591 - val_accuracy: 0.9745\n",
      "Epoch 66/100\n",
      "47909/47909 [==============================] - 80s 2ms/step - loss: 0.1012 - accuracy: 0.9546 - val_loss: 0.1264 - val_accuracy: 0.9431\n",
      "Epoch 67/100\n",
      "47909/47909 [==============================] - 95s 2ms/step - loss: 0.1290 - accuracy: 0.9387 - val_loss: 0.1171 - val_accuracy: 0.9437\n",
      "Epoch 68/100\n",
      "47909/47909 [==============================] - 87s 2ms/step - loss: 0.1264 - accuracy: 0.9399 - val_loss: 0.1185 - val_accuracy: 0.9442\n",
      "Epoch 69/100\n",
      "47909/47909 [==============================] - 82s 2ms/step - loss: 0.1105 - accuracy: 0.9500 - val_loss: 0.0664 - val_accuracy: 0.9724\n",
      "Epoch 70/100\n",
      "47909/47909 [==============================] - 78s 2ms/step - loss: 0.0720 - accuracy: 0.9726 - val_loss: 0.0654 - val_accuracy: 0.9753\n",
      "Epoch 71/100\n",
      "47909/47909 [==============================] - 69s 1ms/step - loss: 0.0695 - accuracy: 0.9726 - val_loss: 0.0685 - val_accuracy: 0.9724\n",
      "Epoch 72/100\n",
      "47909/47909 [==============================] - 67s 1ms/step - loss: 0.0685 - accuracy: 0.9730 - val_loss: 0.0571 - val_accuracy: 0.9767\n",
      "Epoch 73/100\n",
      "47909/47909 [==============================] - 65s 1ms/step - loss: 0.0665 - accuracy: 0.9736 - val_loss: 0.0827 - val_accuracy: 0.9677\n",
      "Epoch 74/100\n",
      "47909/47909 [==============================] - 67s 1ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 0.0589 - val_accuracy: 0.9761\n",
      "Epoch 75/100\n",
      "47909/47909 [==============================] - 71s 1ms/step - loss: 0.0651 - accuracy: 0.9739 - val_loss: 0.0639 - val_accuracy: 0.9732\n",
      "Epoch 76/100\n",
      "47909/47909 [==============================] - 61s 1ms/step - loss: 0.0652 - accuracy: 0.9742 - val_loss: 0.0695 - val_accuracy: 0.9693\n",
      "Epoch 77/100\n",
      "47909/47909 [==============================] - 60s 1ms/step - loss: 0.0661 - accuracy: 0.9737 - val_loss: 0.0606 - val_accuracy: 0.9749\n",
      "Epoch 78/100\n",
      "47909/47909 [==============================] - 61s 1ms/step - loss: 0.0644 - accuracy: 0.9742 - val_loss: 0.0817 - val_accuracy: 0.9705\n",
      "Epoch 79/100\n",
      "47909/47909 [==============================] - 67s 1ms/step - loss: 0.0664 - accuracy: 0.9730 - val_loss: 0.0609 - val_accuracy: 0.9735\n",
      "Epoch 80/100\n",
      "47909/47909 [==============================] - 71s 1ms/step - loss: 0.0656 - accuracy: 0.9736 - val_loss: 0.0624 - val_accuracy: 0.9743\n",
      "Epoch 81/100\n",
      "47909/47909 [==============================] - 61s 1ms/step - loss: 0.0651 - accuracy: 0.9736 - val_loss: 0.0737 - val_accuracy: 0.9701\n",
      "Epoch 82/100\n",
      "47909/47909 [==============================] - 58s 1ms/step - loss: 0.0678 - accuracy: 0.9728 - val_loss: 0.0705 - val_accuracy: 0.9715\n",
      "Epoch 83/100\n",
      "47909/47909 [==============================] - 57s 1ms/step - loss: 0.0671 - accuracy: 0.9732 - val_loss: 0.0576 - val_accuracy: 0.9761\n",
      "Epoch 84/100\n",
      "47909/47909 [==============================] - 57s 1ms/step - loss: 0.0700 - accuracy: 0.9728 - val_loss: 0.0908 - val_accuracy: 0.9704\n",
      "Epoch 85/100\n",
      "47909/47909 [==============================] - 57s 1ms/step - loss: 0.0694 - accuracy: 0.9731 - val_loss: 0.0607 - val_accuracy: 0.9738\n",
      "Epoch 86/100\n",
      "47909/47909 [==============================] - 57s 1ms/step - loss: 0.0669 - accuracy: 0.9735 - val_loss: 0.0819 - val_accuracy: 0.9756\n",
      "Epoch 87/100\n",
      "47909/47909 [==============================] - 59s 1ms/step - loss: 0.0653 - accuracy: 0.9738 - val_loss: 0.0569 - val_accuracy: 0.9761\n",
      "Epoch 88/100\n",
      "47909/47909 [==============================] - 61s 1ms/step - loss: 0.0631 - accuracy: 0.9744 - val_loss: 0.0585 - val_accuracy: 0.9730\n",
      "Epoch 89/100\n",
      "47909/47909 [==============================] - 61s 1ms/step - loss: 0.0644 - accuracy: 0.9745 - val_loss: 0.0598 - val_accuracy: 0.9768\n",
      "Epoch 90/100\n",
      "47909/47909 [==============================] - 60s 1ms/step - loss: 0.0635 - accuracy: 0.9749 - val_loss: 0.0553 - val_accuracy: 0.9765\n",
      "Epoch 91/100\n",
      "47909/47909 [==============================] - 62s 1ms/step - loss: 0.0650 - accuracy: 0.9741 - val_loss: 0.1106 - val_accuracy: 0.9644\n",
      "Epoch 92/100\n",
      "47909/47909 [==============================] - 59s 1ms/step - loss: 0.0654 - accuracy: 0.9743 - val_loss: 0.0550 - val_accuracy: 0.9782\n",
      "Epoch 93/100\n",
      "47909/47909 [==============================] - 62s 1ms/step - loss: 0.0649 - accuracy: 0.9744 - val_loss: 0.0592 - val_accuracy: 0.9761\n",
      "Epoch 94/100\n",
      "47909/47909 [==============================] - 60s 1ms/step - loss: 0.0648 - accuracy: 0.9745 - val_loss: 0.0550 - val_accuracy: 0.9759\n",
      "Epoch 95/100\n",
      "47909/47909 [==============================] - 63s 1ms/step - loss: 0.0634 - accuracy: 0.9754 - val_loss: 0.0577 - val_accuracy: 0.9772\n",
      "Epoch 96/100\n",
      "47909/47909 [==============================] - 68s 1ms/step - loss: 0.0618 - accuracy: 0.9755 - val_loss: 0.0579 - val_accuracy: 0.9771\n",
      "Epoch 97/100\n",
      "47909/47909 [==============================] - 62s 1ms/step - loss: 0.0606 - accuracy: 0.9756 - val_loss: 0.0573 - val_accuracy: 0.9775\n",
      "Epoch 98/100\n",
      "47909/47909 [==============================] - 59s 1ms/step - loss: 0.0627 - accuracy: 0.9754 - val_loss: 0.0615 - val_accuracy: 0.9763\n",
      "Epoch 99/100\n",
      "47909/47909 [==============================] - 66s 1ms/step - loss: 0.0604 - accuracy: 0.9761 - val_loss: 0.0491 - val_accuracy: 0.9789\n",
      "Epoch 100/100\n",
      "47909/47909 [==============================] - 59s 1ms/step - loss: 0.0596 - accuracy: 0.9761 - val_loss: 0.0728 - val_accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ddca8d8d00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_2 = Sequential()\n",
    "#\n",
    "## Adicione as camadas ocultas\n",
    "#model_2.add(Dense(12, input_dim=4, activation='relu'))  # Camada de entrada com 8 neurônios e ativação ReLU\n",
    "#model_2.add(Dense(12, activation='relu'))  # Segunda camada oculta com 3 neurônios e ativação ReLU (opcional)\n",
    "#model_2.add(Dense(8, activation='relu'))\n",
    "#model_2.add(Dense(8, activation='relu'))\n",
    "#\n",
    "## Adicione a camada de saída\n",
    "#model_2.add(Dense(6, activation='softmax'))  # Camada de saída com 5 neurônios (um para cada classe) e ativação Softmax para classificação multiclasse\n",
    "#\n",
    "## Compile o model_2o\n",
    "#model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#\n",
    "## Defina o checkpoint para salvar os pesos\n",
    "#checkpoint = ModelCheckpoint(\"weights_only.h5\", monitor='val_loss', save_best_only=True)\n",
    "#\n",
    "## Treine o model_2o com conjunto de validação e o checkpoint\n",
    "#model_2.fit(X_train_norm, y_train, epochs=100, batch_size=10, validation_data=(X_val_norm, y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9167/9167 [==============================] - 7s 719us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9807957179871812"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_2.predict(X_test_norm)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0:\n",
      "Precision: 0.9643059315143219\n",
      "Recall: 0.9774140377232515\n",
      "F1-score: 0.970815739709349\n",
      "\n",
      "Classe 1:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "Classe 2:\n",
      "Precision: 1.0\n",
      "Recall: 0.9919507575757576\n",
      "F1-score: 0.9959591157594485\n",
      "\n",
      "Classe 3:\n",
      "Precision: 0.9891425694459646\n",
      "Recall: 0.9944322183098592\n",
      "F1-score: 0.9917803408579613\n",
      "\n",
      "Classe 4:\n",
      "Precision: 0.9925182122465053\n",
      "Recall: 0.9493408662900188\n",
      "F1-score: 0.9704495139089422\n",
      "\n",
      "Classe 5:\n",
      "Precision: 0.9864151575722031\n",
      "Recall: 0.968550946057116\n",
      "F1-score: 0.9774014314601012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "for i in range(len(precision)):\n",
    "    print(f'Classe {np.unique(y_test)[i]}:')\n",
    "    print(f'Precision: {precision[i]}')\n",
    "    print(f'Recall: {recall[i]}')\n",
    "    print(f'F1-score: {f1[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3WPetrobras",
   "language": "python",
   "name": "venv3wpetrobras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
